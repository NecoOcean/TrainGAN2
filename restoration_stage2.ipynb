{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é«˜åˆ†è¾¨ç‡å›¾åƒä¿®å¤ä¸å¢å¼ºï¼ˆSR/Restoration GANï¼‰\n",
    "\n",
    "åŸºäº MindSpore æ¡†æ¶å®ç°å›¾åƒè¶…åˆ†è¾¨ç‡é‡å»ºä¸ä¿®å¤\n",
    "é¡¹ç›®ç›®æ ‡\n",
    "- ä½æ¸…å›¾åƒçš„è¶…åˆ†è¾¨ç‡é‡å»ºï¼ˆLRâ†’HRï¼ŒÃ—4æ”¾å¤§ï¼‰\n",
    "- å»å™ªã€å»æ¨¡ç³Šã€å»å‹ç¼©ä¼ªå½±\n",
    "- çœŸå®æ—§ç…§ç‰‡ä¿®å¤ä¸å¢å¼º\n",
    "\n",
    "æŠ€æœ¯è·¯çº¿\n",
    "- **åŸºçº¿æ¨¡å‹**ï¼šSRResNetï¼ˆåƒç´ æŸå¤±è®­ç»ƒï¼Œç¨³å®šæ˜“è®­ï¼‰\n",
    "- **è¿›é˜¶æ¨¡å‹**ï¼šESRGANï¼ˆRRDBNet + RaGAN + æ„ŸçŸ¥æŸå¤±ï¼Œæ„ŸçŸ¥è´¨é‡æ›´å¥½ï¼‰\n",
    "\n",
    "è¯„ä¼°æŒ‡æ ‡\n",
    "- æœ‰GTï¼šPSNRâ†‘ã€SSIMâ†‘\n",
    "- æ— GTï¼šä¸»è§‚è¯„ä»·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. å®‰è£…æ¨¡å—ä¾èµ–\n",
    "\n",
    "#### å…ˆè‡ªè¡Œåˆ›å»ºä¸€ä¸ªpython3.9çš„è™šæ‹Ÿç¯å¢ƒï¼Œå¹¶åœ¨æ­¤ç¯å¢ƒä¸‹å®‰è£…ä¾èµ–\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…pythonä¾èµ–åŒ…ï¼ˆå»ºè®®åœ¨ç»ˆç«¯ä¸‹è½½ä¾èµ–ï¼Œåç»­æ“ä½œç”¨åˆ°å“ªä¸ªè£…å“ªä¸ªï¼Œä¸è¦ä¸€æ¬¡æ€§å…¨éƒ¨å®‰è£…ï¼Œä¼šå‡ºç°ä¾èµ–ç‰ˆæœ¬å†²çªï¼‰\n",
    "# pip install opencv-python Pillow matplotlib scikit-image tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 MindSpore 2.2.14ï¼ˆCPUç‰ˆï¼‰ å®‰è£…å‘½ä»¤\n",
    "#### ä»å®˜ç½‘ä¸‹è½½å®‰è£…wheelåŒ…è¿›è¡Œå®‰è£…ï¼Œé¿å…ä½¿ç”¨pipç›´æ¥å®‰è£…å¯¼è‡´çš„ä¾èµ–å†²çªé—®é¢˜\n",
    "\n",
    "é€‰æ‹©å¯¹åº”çš„æ“ä½œç³»ç»Ÿå’Œpythonç‰ˆæœ¬(å½“å‰æ–‡æ¡£ä½¿ç”¨çš„ç‰ˆæœ¬ä¸ºwindosçš„CPUç‰ˆmindspore): mindspore-2.2.14-cp39-cp39-win_amd64.whl\n",
    "\n",
    "ä¸‹è½½å®ŒwhellåŒ…ä¹‹åå°†.whlæ–‡ä»¶æ”¾åˆ°é¡¹ç›®æ ¹ç›®å½•ä¸‹ã€‚\n",
    "\n",
    "éšåæ‰§è¡Œä»¥ä¸‹å‘½ä»¤(åç»­æ‰€æœ‰çš„ç»ˆç«¯å‘½ä»¤è¯·è‡ªè¡Œå¤åˆ¶åˆ°ç»ˆç«¯è¿è¡Œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… MindSporeï¼ˆé€‚ç”¨äº Windows å’Œ Python 3.9ï¼‰\n",
    "# python -m pip install mindspore-2.2.14-cp39-cp39-win_amd64.whl --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 MindSpore 2.2.14ï¼ˆGPUç‰ˆï¼‰ å®‰è£…å‘½ä»¤ï¼Œé€‚ç”¨äºCUDA 11.6 \n",
    "GPUç‰ˆè¯¦ç»†å®‰è£…å‘½ä»¤è¯·å‚è€ƒå®˜ç½‘ï¼šhttps://gitee.com/mindspore/docs/blob/r2.2/install/mindspore_gpu_install_pip.md\n",
    "\n",
    "GPUç‰ˆæœ¬å®‰è£…å‰éœ€è¦å…ˆå®‰è£…å¯¹åº”ç‰ˆæœ¬çš„CUDAå’ŒCUDNNï¼Œå»ºè®®å‚è€ƒå®˜ç½‘è¯´æ˜è¿›è¡Œå®‰è£…ï¼Œæˆ–è€…ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼ˆä¸ä¼šå®‰è£…å¯ä»¥ç›´æ¥è¯¢é—®AIï¼‰\n",
    "\n",
    "è‹¥æœªå®‰è£…CUDA11.6å’ŒcuDNN8.5.0ï¼Œè¯·å…ˆä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…(è¯·å¤åˆ¶åˆ°ç»ˆç«¯å®‰è£…)\n",
    "\n",
    "PSï¼šMindspore GPUç‰ˆæœ¬åªé€‚ç”¨äºLinuxç³»ç»Ÿï¼Œæœ¬æ–‡æ¡£ç¯å¢ƒä¸º Ubuntu 20.04ç³»ç»Ÿï¼ˆäº‘æœåŠ¡å™¨ï¼‰\n",
    "\n",
    "éœ€è¦ä½¿ç”¨äº‘æœåŠ¡å™¨å¯ä»¥é€‰æ‹©AutoDLï¼Œå¦‚ä½•ä½¿ç”¨å»ºè®®å‚è€ƒBç«™è§†é¢‘ï¼šhttps://www.bilibili.com/video/BV1xDCbYCEZo/?spm_id_from=333.337.search-card.all.click&vd_source=b424755df5875d2c243ba347d8c91dcb\n",
    "\n",
    "äº‘æœåŠ¡å™¨é»˜è®¤æä¾›äº†CUDA11.6å’ŒcuDNN8.5.0ï¼Œæ— éœ€é‡å¤å®‰è£…ï¼Œç›´æ¥æ‰§è¡Œmindsporeå®‰è£…å‘½ä»¤å³å¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äº‘æœåŠ¡å™¨é»˜è®¤æä¾›CUDA 11.6ï¼Œæ— éœ€é¢å¤–å®‰è£…ï¼Œè‹¥å½“å‰äº‘æœåŠ¡å™¨æœªæä¾›CUDA 11.6ï¼Œå¯å‚è€ƒä»¥ä¸‹æ­¥éª¤å®‰è£…\n",
    "# å®‰è£…CUDA 11.6\n",
    "# 1. ä¸‹è½½CUDA 11.6çš„debå®‰è£…åŒ…ï¼ˆçº¦3GBï¼Œç¡®ä¿ç½‘ç»œé€šç•…ï¼‰\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/11.6.0/local_installers/cuda-repo-ubuntu2004-11-6-local_11.6.0-510.39.01-1_amd64.deb\n",
    "\n",
    "# 2. å®‰è£…debåŒ…å¹¶å¯¼å…¥å…¬é’¥\n",
    "# sudo dpkg -i cuda-repo-ubuntu2004-11-6-local_11.6.0-510.39.01-1_amd64.deb\n",
    "# sudo cp /var/cuda-repo-ubuntu2004-11-6-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "\n",
    "# 3. æ›´æ–°è½¯ä»¶æºå¹¶å®‰è£…CUDA 11.6ï¼ˆåŒ…å«é©±åŠ¨ï¼Œè‹¥å·²è£…å…¼å®¹é©±åŠ¨å¯è·³è¿‡é©±åŠ¨å®‰è£…ï¼‰\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install -y cuda-toolkit-11-6  # ä»…å®‰è£…CUDAå·¥å…·åŒ…ï¼ˆæ¨èï¼‰\n",
    "\n",
    "# ç¼–è¾‘ç”¨æˆ·ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼ˆbashç”¨æˆ·ç”¨.bashrcï¼Œzshç”¨æˆ·ç”¨.zshrcï¼‰\n",
    "# nano ~/.bashrc\n",
    "\n",
    "# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ä»¥ä¸‹3è¡Œï¼ˆå¤åˆ¶ç²˜è´´ï¼‰\n",
    "# export PATH=/usr/local/cuda-11.6/bin:$PATH\n",
    "# export LD_LIBRARY_PATH=/usr/local/cuda-11.6/lib64:$LD_LIBRARY_PATH\n",
    "# export CUDA_HOME=/usr/local/cuda-11.6\n",
    "\n",
    "# ä¿å­˜ç”Ÿæ•ˆï¼ˆæŒ‰ Ctrl+O ä¿å­˜ï¼ŒCtrl+X é€€å‡ºnanoï¼‰\n",
    "# source ~/.bashrc\n",
    "\n",
    "# æŸ¥çœ‹CUDAç‰ˆæœ¬ï¼ˆåº”è¾“å‡º11.6ï¼‰\n",
    "# nvcc -V  # æ³¨æ„æ˜¯å¤§å†™V\n",
    "\n",
    "# å®‰è£…cuDNN 8.5.0\n",
    "# è®¿é—® NVIDIA å®˜ç½‘ä¸‹è½½é¡µï¼šhttps://developer.nvidia.com/cudnn-archive\n",
    "# æ‰¾åˆ° Download cuDNN v8.5.0 (August 8th, 2022), for CUDA 11.x\n",
    "\n",
    "# ä¸‹è½½ Local Installer for Linux x86_64 (Tar)åˆ°æœ¬åœ°åç»­ä¸Šä¼ åˆ°LinuxæœåŠ¡å™¨ï¼Œå‡è®¾æ–‡ä»¶åä¸ºcudnn-linux-x86_64-8.5.0.96_cuda11-archive.tar.xz\n",
    "# tar -xJvf cudnn-linux-x86_64-8.5.0.96_cuda11-archive.tar.xz\n",
    "# è¿›å…¥è§£å‹åçš„cuDNNç›®å½•ï¼ˆæ›¿æ¢ä¸ºä½ å®é™…çš„è§£å‹ç›®å½•åï¼‰\n",
    "# cd cudnn-linux-x86_64-8.5.0.96_cuda11-archive\n",
    "\n",
    "# å¤åˆ¶å¤´æ–‡ä»¶åˆ°CUDAçš„includeç›®å½•\n",
    "# sudo cp include/cudnn*.h /usr/local/cuda-11.6/include/\n",
    "\n",
    "# å¤åˆ¶åº“æ–‡ä»¶åˆ°CUDAçš„lib64ç›®å½•ï¼ˆ-Pä¿ç•™ç¬¦å·é“¾æ¥ï¼‰\n",
    "# sudo cp lib64/libcudnn* /usr/local/cuda-11.6/lib64/\n",
    "\n",
    "# ç»™å¤åˆ¶çš„æ–‡ä»¶æ·»åŠ å…¨å±€è¯»å–æƒé™ï¼Œé¿å…åç»­ç¨‹åºæ— æ³•è°ƒç”¨ cuDNN\n",
    "# sudo chmod a+r /usr/local/cuda-11.6/include/cudnn*.h /usr/local/cuda-11.6/lib64/libcudnn*\n",
    "\n",
    "# æ›´æ–°åŠ¨æ€é“¾æ¥åº“ç¼“å­˜\n",
    "# sudo ldconfig /usr/local/cuda-11.6/lib64\n",
    "\n",
    "# æŸ¥çœ‹cuDNNçš„ç‰ˆæœ¬ï¼ˆä»å¤´æ–‡ä»¶ä¸­è¯»å–ï¼‰\n",
    "# cat /usr/local/cuda-11.6/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n",
    "\n",
    "# è‹¥è¾“å‡ºç±»ä¼¼ä»¥ä¸‹å†…å®¹ï¼Œè¯´æ˜å®‰è£…æˆåŠŸï¼š\n",
    "#define CUDNN_MAJOR 8\n",
    "#define CUDNN_MINOR 5\n",
    "#define CUDNN_PATCHLEVEL 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹è½½MindSpore 2.2.14 whlåŒ…\n",
    "# wget https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.2.14/MindSpore/unified/x86_64/mindspore-2.2.14-cp39-cp39-linux_x86_64.whl\n",
    "\n",
    "# å®‰è£…MindSpore\n",
    "# pip install mindspore-2.2.14-cp39-cp39-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. ç¯å¢ƒæ­å»ºä¸éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒéªŒè¯ä¸GPUè¯Šæ–­\n",
    "import mindspore\n",
    "from mindspore import context\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MindSporeç¯å¢ƒè¯Šæ–­ - å›¾åƒä¿®å¤ä¸å¢å¼ºé¡¹ç›®\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. MindSporeç‰ˆæœ¬ä¿¡æ¯\n",
    "print(f\"\\n[MindSporeä¿¡æ¯]\")\n",
    "print(f\"   ç‰ˆæœ¬: {mindspore.__version__}\")\n",
    "print(f\"   å®‰è£…è·¯å¾„: {mindspore.__file__}\")\n",
    "\n",
    "# 2. æ£€æŸ¥CUDAç¯å¢ƒ\n",
    "print(f\"\\n[CUDAç¯å¢ƒæ£€æŸ¥]\")\n",
    "cuda_available = False\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… NVIDIAé©±åŠ¨å·²å®‰è£…\")\n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'CUDA Version' in line or 'GeForce' in line or 'RTX' in line:\n",
    "                print(f\"   {line.strip()}\")\n",
    "        cuda_available = True\n",
    "    else:\n",
    "        print(\"âŒ NVIDIAé©±åŠ¨æœªæ‰¾åˆ°\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ— æ³•æ£€æµ‹NVIDIAé©±åŠ¨: {e}\")\n",
    "\n",
    "# 3. MindSporeè®¾å¤‡æ”¯æŒæ£€æŸ¥\n",
    "print(f\"\\n[MindSporeè®¾å¤‡æ”¯æŒ]\")\n",
    "gpu_supported = False\n",
    "try:\n",
    "    context.set_context(device_target=\"GPU\")\n",
    "    print(f\"âœ… MindSporeæ”¯æŒGPU\")\n",
    "    gpu_supported = True\n",
    "except Exception as e:\n",
    "    print(f\"âŒ MindSporeä¸æ”¯æŒGPUï¼Œä½¿ç”¨CPUæ¨¡å¼\")\n",
    "    context.set_context(device_target=\"CPU\")\n",
    "\n",
    "# 4. å½“å‰è®¾å¤‡çŠ¶æ€\n",
    "print(f\"\\n[å½“å‰è®¾å¤‡çŠ¶æ€]\")\n",
    "current_device = context.get_context('device_target')\n",
    "print(f\"   ä½¿ç”¨è®¾å¤‡: {current_device}\")\n",
    "\n",
    "# 5. æ€»ç»“\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"è¯Šæ–­æ€»ç»“\")\n",
    "print(\"=\" * 60)\n",
    "if gpu_supported and cuda_available:\n",
    "    print(\"âœ… GPUç¯å¢ƒå®Œæ•´ï¼Œå¯ä»¥ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒ\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  å½“å‰ç¯å¢ƒä½¿ç”¨CPUæ¨¡å¼ï¼ˆè®­ç»ƒé€Ÿåº¦è¾ƒæ…¢ä½†åŠŸèƒ½å®Œæ•´ï¼‰\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. æ•°æ®é›†åŠ è½½ä¸é¢„å¤„ç†\n",
    "\n",
    "æ•°æ®ç›®å½•ç»“æ„ï¼š\n",
    "```\n",
    "./data/\n",
    "  train_HR/    # è®­ç»ƒé«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆGround Truthï¼‰\n",
    "  train_LR/    # è®­ç»ƒä½åˆ†è¾¨ç‡/åŠ£åŒ–å›¾åƒï¼ˆä¸HRé…å¯¹ï¼‰\n",
    "  val_HR/      # éªŒè¯é«˜åˆ†è¾¨ç‡å›¾åƒ\n",
    "  val_LR/      # éªŒè¯ä½åˆ†è¾¨ç‡å›¾åƒ\n",
    "  old_photos/  # çœŸå®æ—§ç…§ç‰‡ï¼ˆæ— GTï¼Œç”¨äºæ¨ç†å±•ç¤ºï¼‰\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®é›†ç»Ÿè®¡ä¸æ£€æŸ¥\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# é…ç½®\n",
    "DATA_ROOT = \"./data\"\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "def count_images(directory):\n",
    "    \"\"\"ç»Ÿè®¡ç›®å½•ä¸‹çš„å›¾ç‰‡æ•°é‡\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0, []\n",
    "    files = [f for f in os.listdir(directory) \n",
    "             if f.lower().endswith(IMAGE_EXTENSIONS) and os.path.isfile(os.path.join(directory, f))]\n",
    "    return len(files), sorted(files)\n",
    "\n",
    "# ç»Ÿè®¡å„æ•°æ®é›†\n",
    "print(\"=\" * 60)\n",
    "print(\"æ•°æ®é›†ç»Ÿè®¡\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "datasets = {\n",
    "    'train_HR': os.path.join(DATA_ROOT, 'train_HR'),\n",
    "    'train_LR': os.path.join(DATA_ROOT, 'train_LR'),\n",
    "    'val_HR': os.path.join(DATA_ROOT, 'val_HR'),\n",
    "    'val_LR': os.path.join(DATA_ROOT, 'val_LR'),\n",
    "    'old_photos': os.path.join(DATA_ROOT, 'old_photos')\n",
    "}\n",
    "\n",
    "for name, path in datasets.items():\n",
    "    count, files = count_images(path)\n",
    "    print(f\"{name}: {count} å¼ å›¾åƒ\")\n",
    "    if count > 0:\n",
    "        print(f\"   ç¤ºä¾‹: {files[:3]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆå¯¹æ•°æ®é›†åŠ è½½å™¨ï¼ˆå†…å­˜é¢„åŠ è½½ç‰ˆæœ¬ + æ•°æ®å¢å¼ºï¼‰\n",
    "import os\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.vision as vision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===================== æ•°æ®é…ç½®å‚æ•°ï¼ˆå¹³è¡¡ç‰ˆï¼šGPUåˆ©ç”¨ç‡ + è®­ç»ƒé€Ÿåº¦ï¼‰ =====================\n",
    "DATA_ROOT = \"./data\"\n",
    "SCALE = 4  # è¶…åˆ†è¾¨ç‡æ”¾å¤§å€æ•°\n",
    "HR_SIZE = 192  # HR patchå°ºå¯¸ï¼ˆä¿æŒ192ï¼Œé¿å…è¿‡é•¿è®­ç»ƒæ—¶é—´ï¼‰\n",
    "LR_SIZE = HR_SIZE // SCALE  # LR patchå°ºå¯¸\n",
    "BATCH_SIZE = 16  # æ‰¹å¤§å°\n",
    "NUM_WORKERS = 1  # å†…å­˜é¢„åŠ è½½æ¨¡å¼ä¸‹è®¾ä¸º1å³å¯\n",
    "MAX_TRAIN_SAMPLES = None  # è®­ç»ƒé›†æœ€å¤§åŠ è½½æ•°é‡ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨éƒ¨\n",
    "MAX_VAL_SAMPLES = None    # éªŒè¯é›†æœ€å¤§åŠ è½½æ•°é‡ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨éƒ¨\n",
    "USE_AUGMENTATION = True   # æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼º\n",
    "\n",
    "# ä¸ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼ˆèŠ‚çœè®­ç»ƒæ—¶é—´ï¼‰\n",
    "ACCUMULATION_STEPS = 1    # è®¾ä¸º1è¡¨ç¤ºä¸ç´¯ç§¯\n",
    "# ====================================================================================\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def get_paired_paths(hr_dir, lr_dir, scale=4, max_samples=None):\n",
    "    \"\"\"è·å–é…å¯¹çš„HR/LRå›¾åƒè·¯å¾„\n",
    "    \n",
    "    æ”¯æŒå¤„ç†æ–‡ä»¶åä¸­åŒ…å«ç©ºæ ¼çš„æƒ…å†µ\n",
    "    HRæ–‡ä»¶åæ ¼å¼ï¼š{stem}.{ext}ï¼ˆå¯èƒ½åŒ…å«ç©ºæ ¼ï¼‰\n",
    "    LRæ–‡ä»¶åæ ¼å¼ï¼š{stem}x{scale}.png æˆ– {stem} x{scale}.png\n",
    "    \n",
    "    Args:\n",
    "        hr_dir: HRå›¾åƒç›®å½•\n",
    "        lr_dir: LRå›¾åƒç›®å½•\n",
    "        scale: æ”¾å¤§å€æ•°\n",
    "        max_samples: æœ€å¤§åŠ è½½æ•°é‡ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨éƒ¨\n",
    "    \"\"\"\n",
    "    hr_files = sorted([f for f in os.listdir(hr_dir) if f.lower().endswith(IMAGE_EXTENSIONS)])\n",
    "    lr_files = os.listdir(lr_dir)\n",
    "    paired = []\n",
    "    \n",
    "    for hr_name in hr_files:\n",
    "        stem, ext = os.path.splitext(hr_name)\n",
    "        hr_path = os.path.join(hr_dir, hr_name)\n",
    "        \n",
    "        # å°è¯•å¤šç§LRæ–‡ä»¶åæ ¼å¼\n",
    "        lr_candidates = [\n",
    "            f\"{stem}x{scale}.png\",           # æ ‡å‡†æ ¼å¼ï¼š0003x4.png\n",
    "            f\"{stem} x{scale}.png\",          # å¸¦ç©ºæ ¼ï¼š0001 x4.png\n",
    "            f\"{stem.strip()}x{scale}.png\",   # å»é™¤stemæœ«å°¾ç©ºæ ¼\n",
    "        ]\n",
    "        \n",
    "        lr_path = None\n",
    "        for lr_name in lr_candidates:\n",
    "            candidate_path = os.path.join(lr_dir, lr_name)\n",
    "            if os.path.exists(candidate_path):\n",
    "                lr_path = candidate_path\n",
    "                break\n",
    "        \n",
    "        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…\n",
    "        if lr_path is None:\n",
    "            stem_clean = stem.strip()\n",
    "            for f in lr_files:\n",
    "                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«stemå’Œscaleæ ‡è®°\n",
    "                f_stem = os.path.splitext(f)[0]\n",
    "                if f_stem.strip().replace(' ', '').startswith(stem_clean.replace(' ', '')) and f'x{scale}' in f:\n",
    "                    lr_path = os.path.join(lr_dir, f)\n",
    "                    break\n",
    "        \n",
    "        if lr_path and os.path.exists(lr_path):\n",
    "            paired.append((hr_path, lr_path))\n",
    "            # è¾¾åˆ°æœ€å¤§æ•°é‡æ—¶æå‰é€€å‡º\n",
    "            if max_samples is not None and len(paired) >= max_samples:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"è­¦å‘Š: æœªæ‰¾åˆ°é…å¯¹LR: {hr_name} -> å°è¯•è¿‡: {lr_candidates[:2]}\")\n",
    "    \n",
    "    return paired\n",
    "\n",
    "def preprocess_image(img, target_size):\n",
    "    \"\"\"é¢„å¤„ç†å•å¼ å›¾åƒï¼šç¡®ä¿å°ºå¯¸è¶³å¤Ÿ\"\"\"\n",
    "    w, h = img.size\n",
    "    if w < target_size or h < target_size:\n",
    "        new_w = max(w, target_size)\n",
    "        new_h = max(h, target_size)\n",
    "        img = img.resize((new_w, new_h), Image.BICUBIC)\n",
    "    return img\n",
    "\n",
    "def augment_pair(hr_crop, lr_crop):\n",
    "    \"\"\"å¯¹HRå’ŒLRå›¾åƒå¯¹åŒæ—¶åº”ç”¨æ•°æ®å¢å¼º\n",
    "    \n",
    "    å¢å¼ºæ–¹å¼ï¼ˆéšæœºé€‰æ‹©ï¼‰ï¼š\n",
    "    - æ°´å¹³ç¿»è½¬ (50%æ¦‚ç‡)\n",
    "    - å‚ç›´ç¿»è½¬ (50%æ¦‚ç‡)\n",
    "    - æ—‹è½¬90Â°çš„å€æ•° (éšæœº0/90/180/270åº¦)\n",
    "    \n",
    "    æ³¨æ„ï¼šå¿…é¡»å¯¹HRå’ŒLRåº”ç”¨ç›¸åŒçš„å˜æ¢ä»¥ä¿æŒé…å¯¹ä¸€è‡´æ€§\n",
    "    \"\"\"\n",
    "    # éšæœºæ°´å¹³ç¿»è½¬\n",
    "    if np.random.random() < 0.5:\n",
    "        hr_crop = np.flip(hr_crop, axis=1).copy()\n",
    "        lr_crop = np.flip(lr_crop, axis=1).copy()\n",
    "    \n",
    "    # éšæœºå‚ç›´ç¿»è½¬\n",
    "    if np.random.random() < 0.5:\n",
    "        hr_crop = np.flip(hr_crop, axis=0).copy()\n",
    "        lr_crop = np.flip(lr_crop, axis=0).copy()\n",
    "    \n",
    "    # éšæœºæ—‹è½¬90Â°çš„å€æ•° (0, 1, 2, 3 åˆ†åˆ«å¯¹åº” 0Â°, 90Â°, 180Â°, 270Â°)\n",
    "    k = np.random.randint(0, 4)\n",
    "    if k > 0:\n",
    "        hr_crop = np.rot90(hr_crop, k).copy()\n",
    "        lr_crop = np.rot90(lr_crop, k).copy()\n",
    "    \n",
    "    return hr_crop, lr_crop\n",
    "\n",
    "class PairedDataGenerator:\n",
    "    \"\"\"æˆå¯¹æ•°æ®ç”Ÿæˆå™¨ï¼ˆå†…å­˜é¢„åŠ è½½ç‰ˆæœ¬ + æ•°æ®å¢å¼ºï¼‰\n",
    "    \n",
    "    åœ¨åˆå§‹åŒ–æ—¶å°†æ‰€æœ‰å›¾åƒåŠ è½½åˆ°å†…å­˜ï¼Œè®­ç»ƒæ—¶ç›´æ¥ä»å†…å­˜è¯»å–ï¼Œ\n",
    "    æ¶ˆé™¤ç£ç›˜I/Oå»¶è¿Ÿï¼Œå¤§å¹…æå‡GPUåˆ©ç”¨ç‡ã€‚\n",
    "    \n",
    "    æ•°æ®å¢å¼ºï¼šéšæœºç¿»è½¬ + éšæœºæ—‹è½¬ï¼Œæœ‰æ•ˆæ•°æ®é‡å¢åŠ 8å€\n",
    "    \"\"\"\n",
    "    def __init__(self, hr_dir, lr_dir, hr_size=128, scale=4, is_train=True, max_samples=None, use_augmentation=True):\n",
    "        self.pairs = get_paired_paths(hr_dir, lr_dir, scale, max_samples)\n",
    "        self.hr_size = hr_size\n",
    "        self.lr_size = hr_size // scale\n",
    "        self.scale = scale\n",
    "        self.is_train = is_train\n",
    "        self.use_augmentation = use_augmentation and is_train  # åªåœ¨è®­ç»ƒæ—¶å¢å¼º\n",
    "        \n",
    "        # å†…å­˜é¢„åŠ è½½æ‰€æœ‰å›¾åƒ\n",
    "        self.hr_images = []\n",
    "        self.lr_images = []\n",
    "        \n",
    "        if len(self.pairs) > 0:\n",
    "            print(f\"ğŸ“¥ é¢„åŠ è½½ {len(self.pairs)} å¯¹å›¾åƒåˆ°å†…å­˜...\")\n",
    "            for hr_path, lr_path in tqdm(self.pairs, desc=\"åŠ è½½å›¾åƒ\", unit=\"å¼ \"):\n",
    "                # è¯»å–å¹¶é¢„å¤„ç†HRå›¾åƒ\n",
    "                hr_img = Image.open(hr_path).convert('RGB')\n",
    "                hr_img = preprocess_image(hr_img, hr_size)\n",
    "                self.hr_images.append(np.array(hr_img))\n",
    "                \n",
    "                # è¯»å–å¹¶é¢„å¤„ç†LRå›¾åƒ\n",
    "                lr_img = Image.open(lr_path).convert('RGB')\n",
    "                lr_img = preprocess_image(lr_img, self.lr_size)\n",
    "                self.lr_images.append(np.array(lr_img))\n",
    "            \n",
    "            # è®¡ç®—å†…å­˜å ç”¨\n",
    "            hr_mem = sum(img.nbytes for img in self.hr_images) / 1024 / 1024\n",
    "            lr_mem = sum(img.nbytes for img in self.lr_images) / 1024 / 1024\n",
    "            print(f\"âœ… é¢„åŠ è½½å®Œæˆï¼å†…å­˜å ç”¨: HR={hr_mem:.1f}MB, LR={lr_mem:.1f}MB, æ€»è®¡={hr_mem+lr_mem:.1f}MB\")\n",
    "            print(f\"   ç¤ºä¾‹é…å¯¹: {os.path.basename(self.pairs[0][0])} <-> {os.path.basename(self.pairs[0][1])}\")\n",
    "            if self.use_augmentation:\n",
    "                print(f\"   ğŸ”„ æ•°æ®å¢å¼ºå·²å¯ç”¨ï¼ˆæœ‰æ•ˆæ•°æ®é‡ Ã—8ï¼‰\")\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        hr_img = self.hr_images[index]\n",
    "        lr_img = self.lr_images[index]\n",
    "        \n",
    "        hr_h, hr_w = hr_img.shape[:2]\n",
    "        lr_h, lr_w = lr_img.shape[:2]\n",
    "        \n",
    "        # éšæœºè£å‰ªä½ç½®ï¼ˆåŸºäºHRåæ ‡ï¼‰\n",
    "        max_x = max(0, hr_w - self.hr_size)\n",
    "        max_y = max(0, hr_h - self.hr_size)\n",
    "        x = np.random.randint(0, max_x + 1) if max_x > 0 else 0\n",
    "        y = np.random.randint(0, max_y + 1) if max_y > 0 else 0\n",
    "        \n",
    "        # è£å‰ªHR\n",
    "        hr_crop = hr_img[y:y+self.hr_size, x:x+self.hr_size]\n",
    "        \n",
    "        # å¯¹åº”ä½ç½®è£å‰ªLRï¼ˆæŒ‰æ¯”ä¾‹ç¼©æ”¾åæ ‡ï¼‰\n",
    "        lx = min(x // self.scale, max(0, lr_w - self.lr_size))\n",
    "        ly = min(y // self.scale, max(0, lr_h - self.lr_size))\n",
    "        lr_crop = lr_img[ly:ly+self.lr_size, lx:lx+self.lr_size]\n",
    "        \n",
    "        # æ•°æ®å¢å¼ºï¼ˆä»…è®­ç»ƒæ—¶ï¼‰\n",
    "        if self.use_augmentation:\n",
    "            hr_crop, lr_crop = augment_pair(hr_crop, lr_crop)\n",
    "        \n",
    "        # å½’ä¸€åŒ–åˆ°[-1, 1]å¹¶è½¬æ¢ä¸ºCHWæ ¼å¼\n",
    "        hr_np = hr_crop.astype(np.float32) / 127.5 - 1.0\n",
    "        lr_np = lr_crop.astype(np.float32) / 127.5 - 1.0\n",
    "        \n",
    "        # HWC -> CHW\n",
    "        hr_np = hr_np.transpose(2, 0, 1)\n",
    "        lr_np = lr_np.transpose(2, 0, 1)\n",
    "        \n",
    "        return hr_np, lr_np\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "def create_sr_dataset(hr_dir, lr_dir, hr_size=128, scale=4, batch_size=4, is_train=True, max_samples=None, use_augmentation=True):\n",
    "    \"\"\"åˆ›å»ºè¶…åˆ†è¾¨ç‡æ•°æ®é›†\n",
    "    \n",
    "    Args:\n",
    "        hr_dir: HRå›¾åƒç›®å½•\n",
    "        lr_dir: LRå›¾åƒç›®å½•\n",
    "        hr_size: HR patchå°ºå¯¸\n",
    "        scale: æ”¾å¤§å€æ•°\n",
    "        batch_size: æ‰¹å¤§å°\n",
    "        is_train: æ˜¯å¦ä¸ºè®­ç»ƒé›†\n",
    "        max_samples: æœ€å¤§åŠ è½½æ•°é‡ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨éƒ¨\n",
    "        use_augmentation: æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼º\n",
    "    \n",
    "    æ³¨æ„: batch_sizeå¿…é¡»å°äºæ•°æ®é‡ï¼Œå¦åˆ™ä¼šå› drop_remainder=Trueå¯¼è‡´0ä¸ªbatch\n",
    "    \"\"\"\n",
    "    generator = PairedDataGenerator(hr_dir, lr_dir, hr_size, scale, is_train, max_samples, use_augmentation)\n",
    "    \n",
    "    if len(generator) == 0:\n",
    "        print(f\"âŒ æœªæ‰¾åˆ°é…å¯¹æ•°æ®ï¼è¯·æ£€æŸ¥ç›®å½•: {hr_dir} å’Œ {lr_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # æ£€æŸ¥batch_sizeæ˜¯å¦åˆç†\n",
    "    if batch_size > len(generator):\n",
    "        print(f\"âš ï¸ è­¦å‘Š: BATCH_SIZE({batch_size}) > æ•°æ®é‡({len(generator)})ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸º {len(generator)}\")\n",
    "        batch_size = len(generator)\n",
    "    \n",
    "    dataset = ds.GeneratorDataset(\n",
    "        source=generator,\n",
    "        column_names=[\"hr\", \"lr\"],\n",
    "        shuffle=is_train,\n",
    "        num_parallel_workers=NUM_WORKERS  # å†…å­˜é¢„åŠ è½½æ¨¡å¼ä¸‹è®¾ä¸º1\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "# åˆ›å»ºæ•°æ®é›†\n",
    "print(\"\\n=== åˆ›å»ºæ•°æ®é›†ï¼ˆå†…å­˜é¢„åŠ è½½æ¨¡å¼ + æ•°æ®å¢å¼ºï¼‰ ===\")\n",
    "train_dataset = create_sr_dataset(\n",
    "    os.path.join(DATA_ROOT, 'train_HR'),\n",
    "    os.path.join(DATA_ROOT, 'train_LR'),\n",
    "    hr_size=HR_SIZE, scale=SCALE, batch_size=BATCH_SIZE, is_train=True,\n",
    "    max_samples=MAX_TRAIN_SAMPLES,  # è®­ç»ƒé›†åŠ è½½æ•°é‡é™åˆ¶\n",
    "    use_augmentation=USE_AUGMENTATION  # è®­ç»ƒé›†å¯ç”¨æ•°æ®å¢å¼º\n",
    ")\n",
    "\n",
    "val_dataset = create_sr_dataset(\n",
    "    os.path.join(DATA_ROOT, 'val_HR'),\n",
    "    os.path.join(DATA_ROOT, 'val_LR'),\n",
    "    hr_size=HR_SIZE, scale=SCALE, batch_size=1, is_train=False,\n",
    "    max_samples=MAX_VAL_SAMPLES,  # éªŒè¯é›†åŠ è½½æ•°é‡é™åˆ¶\n",
    "    use_augmentation=False  # éªŒè¯é›†ä¸åšå¢å¼º\n",
    ")\n",
    "\n",
    "if train_dataset and val_dataset:\n",
    "    print(f\"\\nè®­ç»ƒé›†æ‰¹æ¬¡æ•°: {train_dataset.get_dataset_size()}\")\n",
    "    print(f\"éªŒè¯é›†æ‰¹æ¬¡æ•°: {val_dataset.get_dataset_size()}\")\n",
    "else:\n",
    "    print(\"\\nâŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®ç›®å½•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ•°æ®æ ·æœ¬\n",
    "def denormalize(img):\n",
    "    \"\"\"åå½’ä¸€åŒ–: [-1,1] -> [0,255]\"\"\"\n",
    "    img = (img * 127.5 + 127.5).clip(0, 255).astype(np.uint8)\n",
    "    if img.shape[0] == 3:  # CHW -> HWC\n",
    "        img = img.transpose(1, 2, 0)\n",
    "    return img\n",
    "\n",
    "# è·å–ä¸€ä¸ªbatchè¿›è¡Œå¯è§†åŒ–\n",
    "try:\n",
    "    sample = next(train_dataset.create_dict_iterator())\n",
    "    hr_batch = sample['hr'].asnumpy()\n",
    "    lr_batch = sample['lr'].asnumpy()\n",
    "    \n",
    "    print(f\"HR shape: {hr_batch.shape}\")\n",
    "    print(f\"LR shape: {lr_batch.shape}\")\n",
    "    \n",
    "    # å¯è§†åŒ–å‰2å¯¹\n",
    "    n_show = min(2, hr_batch.shape[0])\n",
    "    fig, axes = plt.subplots(n_show, 2, figsize=(10, 5*n_show))\n",
    "    if n_show == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(n_show):\n",
    "        hr_img = denormalize(hr_batch[i])\n",
    "        lr_img = denormalize(lr_batch[i])\n",
    "        \n",
    "        axes[i, 0].imshow(lr_img)\n",
    "        axes[i, 0].set_title(f'LR ({lr_img.shape[0]}x{lr_img.shape[1]})')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(hr_img)\n",
    "        axes[i, 1].set_title(f'HR ({hr_img.shape[0]}x{hr_img.shape[1]})')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.suptitle('Training Data Samples (LR / HR Pairs)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\nâœ… æ•°æ®åŠ è½½éªŒè¯æˆåŠŸï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®å¯è§†åŒ–å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. æ¨¡å‹æ¶æ„\n",
    "\n",
    "### 3.1 SRResNet åŸºçº¿ç”Ÿæˆå™¨\n",
    "- 16ä¸ªæ®‹å·®å—\n",
    "- äºšåƒç´ å·ç§¯ï¼ˆPixelShuffleï¼‰ä¸Šé‡‡æ ·\n",
    "- é€‚åˆåƒç´ çº§æŸå¤±è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRResNet ç”Ÿæˆå™¨\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "from mindspore.common.initializer import Normal, HeNormal\n",
    "\n",
    "class ResidualBlock(nn.Cell):\n",
    "    \"\"\"æ®‹å·®å—ï¼šConv-BN-PReLU-Conv-BN + Skip\"\"\"\n",
    "    def __init__(self, channels=64):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1, pad_mode='pad', \n",
    "                               has_bias=False, weight_init=HeNormal())\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1, pad_mode='pad',\n",
    "                               has_bias=False, weight_init=HeNormal())\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def construct(self, x):\n",
    "        residual = x\n",
    "        out = self.prelu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return out + residual\n",
    "\n",
    "class PixelShuffle(nn.Cell):\n",
    "    \"\"\"äºšåƒç´ å·ç§¯ä¸Šé‡‡æ · - ä¸PyTorchå…¼å®¹çš„æ‰‹åŠ¨å®ç°\n",
    "    \n",
    "    å°† (N, C*r*r, H, W) å˜æ¢ä¸º (N, C, H*r, W*r)\n",
    "    ä½¿ç”¨æ­£ç¡®çš„é€šé“é‡æ’é¡ºåºï¼Œé¿å…æ£‹ç›˜æ ¼ä¼ªå½±\n",
    "    \"\"\"\n",
    "    def __init__(self, scale):\n",
    "        super(PixelShuffle, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.reshape = ops.Reshape()\n",
    "        self.transpose = ops.Transpose()\n",
    "    \n",
    "    def construct(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        r = self.scale\n",
    "        out_c = c // (r * r)\n",
    "        \n",
    "        # (N, C*r*r, H, W) -> (N, out_c, r, r, H, W)\n",
    "        x = self.reshape(x, (n, out_c, r, r, h, w))\n",
    "        # (N, out_c, r, r, H, W) -> (N, out_c, H, r, W, r)\n",
    "        x = self.transpose(x, (0, 1, 4, 2, 5, 3))\n",
    "        # (N, out_c, H, r, W, r) -> (N, out_c, H*r, W*r)\n",
    "        x = self.reshape(x, (n, out_c, h * r, w * r))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UpsampleBlock(nn.Cell):\n",
    "    \"\"\"ä¸Šé‡‡æ ·å—ï¼šConv + PixelShuffle + PReLU\"\"\"\n",
    "    def __init__(self, in_channels, scale=2):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * (scale ** 2), 3, \n",
    "                              padding=1, pad_mode='pad', has_bias=False, weight_init=HeNormal())\n",
    "        self.pixel_shuffle = PixelShuffle(scale)\n",
    "        self.prelu = nn.PReLU()\n",
    "    \n",
    "    def construct(self, x):\n",
    "        return self.prelu(self.pixel_shuffle(self.conv(x)))\n",
    "\n",
    "class SRResNet(nn.Cell):\n",
    "    \"\"\"SRResNet è¶…åˆ†è¾¨ç‡ç”Ÿæˆå™¨\n",
    "    \n",
    "    Args:\n",
    "        scale: æ”¾å¤§å€æ•°ï¼ˆ2, 3, 4ï¼‰\n",
    "        n_residual: æ®‹å·®å—æ•°é‡\n",
    "        n_features: ç‰¹å¾é€šé“æ•°\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=4, n_residual=16, n_features=64):\n",
    "        super(SRResNet, self).__init__()\n",
    "        self.scale = scale\n",
    "        \n",
    "        # è¾“å…¥å·ç§¯\n",
    "        self.conv_input = nn.Conv2d(3, n_features, 9, padding=4, pad_mode='pad',\n",
    "                                    has_bias=False, weight_init=HeNormal())\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "        # æ®‹å·®å—\n",
    "        self.residual_blocks = nn.SequentialCell(\n",
    "            [ResidualBlock(n_features) for _ in range(n_residual)]\n",
    "        )\n",
    "        \n",
    "        # æ®‹å·®åå·ç§¯\n",
    "        self.conv_mid = nn.Conv2d(n_features, n_features, 3, padding=1, pad_mode='pad',\n",
    "                                  has_bias=False, weight_init=HeNormal())\n",
    "        self.bn_mid = nn.BatchNorm2d(n_features)\n",
    "        \n",
    "        # ä¸Šé‡‡æ ·ï¼ˆÃ—4 = ä¸¤æ¬¡Ã—2ï¼‰\n",
    "        upsample_layers = []\n",
    "        if scale == 4:\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 2))\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 2))\n",
    "        elif scale == 2:\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 2))\n",
    "        elif scale == 3:\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 3))\n",
    "        self.upsample = nn.SequentialCell(upsample_layers)\n",
    "        \n",
    "        # è¾“å‡ºå·ç§¯\n",
    "        self.conv_output = nn.Conv2d(n_features, 3, 9, padding=4, pad_mode='pad',\n",
    "                                     has_bias=False, weight_init=HeNormal())\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def construct(self, x):\n",
    "        # è¾“å…¥å¤„ç†\n",
    "        out = self.prelu(self.conv_input(x))\n",
    "        residual = out\n",
    "        \n",
    "        # æ®‹å·®å—\n",
    "        out = self.residual_blocks(out)\n",
    "        out = self.bn_mid(self.conv_mid(out))\n",
    "        out = out + residual\n",
    "        \n",
    "        # ä¸Šé‡‡æ ·\n",
    "        out = self.upsample(out)\n",
    "        \n",
    "        # è¾“å‡º\n",
    "        out = self.tanh(self.conv_output(out))\n",
    "        return out\n",
    "\n",
    "# éªŒè¯ç”Ÿæˆå™¨\n",
    "print(\"=== SRResNet æ¨¡å‹éªŒè¯ ===\")\n",
    "generator = SRResNet(scale=SCALE, n_residual=16, n_features=64)\n",
    "test_lr = Tensor(np.random.randn(1, 3, LR_SIZE, LR_SIZE).astype(np.float32))\n",
    "test_sr = generator(test_lr)\n",
    "print(f\"è¾“å…¥ LR: {test_lr.shape}\")\n",
    "print(f\"è¾“å‡º SR: {test_sr.shape}\")\n",
    "print(f\"æœŸæœ› HR: (1, 3, {HR_SIZE}, {HR_SIZE})\")\n",
    "assert test_sr.shape == (1, 3, HR_SIZE, HR_SIZE), \"è¾“å‡ºå°ºå¯¸ä¸åŒ¹é…ï¼\"\n",
    "print(\"âœ… SRResNet æ„å»ºæˆåŠŸï¼\")\n",
    "\n",
    "# éªŒè¯PixelShuffleæ­£ç¡®æ€§\n",
    "print(\"\\n=== PixelShuffle éªŒè¯ ===\")\n",
    "ps = PixelShuffle(2)\n",
    "# åˆ›å»ºæµ‹è¯•è¾“å…¥ï¼šæ¯ä¸ªr*rå—å†…çš„å€¼åº”è¯¥æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—\n",
    "test_input = Tensor(np.arange(16).reshape(1, 16, 1, 1).astype(np.float32))\n",
    "test_output = ps(test_input)\n",
    "print(f\"è¾“å…¥shape: {test_input.shape} -> è¾“å‡ºshape: {test_output.shape}\")\n",
    "print(f\"è¾“å‡ºå†…å®¹:\\n{test_output.asnumpy()[0, 0]}\")\n",
    "# æ­£ç¡®çš„PixelShuffleåº”è¯¥è¾“å‡º:\n",
    "# [[0, 1], [2, 3]] å¯¹åº”ç¬¬ä¸€ä¸ªè¾“å‡ºé€šé“\n",
    "print(\"âœ… PixelShuffle éªŒè¯å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ESRGAN åˆ¤åˆ«å™¨ï¼ˆPatchGANï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESRGAN åˆ¤åˆ«å™¨ï¼ˆè‡ªé€‚åº”è¾“å…¥å°ºå¯¸ï¼‰\n",
    "class Discriminator(nn.Cell):\n",
    "    \"\"\"VGGé£æ ¼åˆ¤åˆ«å™¨\n",
    "    \n",
    "    ä½¿ç”¨è‡ªé€‚åº”å¹³å‡æ± åŒ–ï¼Œæ”¯æŒä¸åŒå°ºå¯¸çš„HRè¾“å…¥\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def conv_block(in_ch, out_ch, stride=1, bn=True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, \n",
    "                         pad_mode='pad', has_bias=not bn, weight_init=HeNormal())\n",
    "            ]\n",
    "            if bn:\n",
    "                layers.append(nn.BatchNorm2d(out_ch))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "            return nn.SequentialCell(layers)\n",
    "        \n",
    "        self.features = nn.SequentialCell([\n",
    "            # æ— BNçš„ç¬¬ä¸€å±‚\n",
    "            conv_block(in_channels, ndf, stride=1, bn=False),\n",
    "            conv_block(ndf, ndf, stride=2, bn=True),\n",
    "            # H/2\n",
    "            conv_block(ndf, ndf*2, stride=1, bn=True),\n",
    "            conv_block(ndf*2, ndf*2, stride=2, bn=True),\n",
    "            # H/4\n",
    "            conv_block(ndf*2, ndf*4, stride=1, bn=True),\n",
    "            conv_block(ndf*4, ndf*4, stride=2, bn=True),\n",
    "            # H/8\n",
    "            conv_block(ndf*4, ndf*8, stride=1, bn=True),\n",
    "            conv_block(ndf*8, ndf*8, stride=2, bn=True),\n",
    "            # H/16\n",
    "        ])\n",
    "        \n",
    "        # ä½¿ç”¨è‡ªé€‚åº”å¹³å‡æ± åŒ–ï¼Œå°†ä»»æ„å°ºå¯¸ç‰¹å¾å›¾è½¬æ¢ä¸ºå›ºå®šçš„4x4\n",
    "        self.adaptive_pool = ops.AdaptiveAvgPool2D((4, 4))\n",
    "        \n",
    "        # åˆ†ç±»å¤´ï¼ˆè¾“å…¥å›ºå®šä¸º ndf*8 * 4 * 4 = 512 * 16 = 8192ï¼‰\n",
    "        self.classifier = nn.SequentialCell([\n",
    "            nn.Flatten(),\n",
    "            nn.Dense(ndf*8 * 4 * 4, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dense(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "    \n",
    "    def construct(self, x):\n",
    "        features = self.features(x)\n",
    "        # è‡ªé€‚åº”æ± åŒ–åˆ°å›ºå®šå°ºå¯¸\n",
    "        features = self.adaptive_pool(features)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "# éªŒè¯åˆ¤åˆ«å™¨\n",
    "print(\"\\n=== Discriminator æ¨¡å‹éªŒè¯ ===\")\n",
    "discriminator = Discriminator(in_channels=3, ndf=64)\n",
    "test_hr = Tensor(np.random.randn(1, 3, HR_SIZE, HR_SIZE).astype(np.float32))\n",
    "test_out = discriminator(test_hr)\n",
    "print(f\"è¾“å…¥ HR: {test_hr.shape}\")\n",
    "print(f\"è¾“å‡º: {test_out.shape}\")\n",
    "print(\"âœ… Discriminator æ„å»ºæˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. æŸå¤±å‡½æ•°\n",
    "\n",
    "- **åƒç´ æŸå¤±ï¼ˆL1ï¼‰**ï¼šä¿è¯åƒç´ çº§å‡†ç¡®æ€§\n",
    "- **æ„ŸçŸ¥æŸå¤±ï¼ˆVGGï¼‰**ï¼šä¿è¯æ„ŸçŸ¥è´¨é‡ï¼ˆå¯é€‰ï¼‰\n",
    "- **å¯¹æŠ—æŸå¤±ï¼ˆGANï¼‰**ï¼šç”Ÿæˆæ›´çœŸå®çš„ç»†èŠ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸå¤±å‡½æ•°å®šä¹‰\n",
    "class SRLoss(nn.Cell):\n",
    "    \"\"\"è¶…åˆ†è¾¨ç‡ç»¼åˆæŸå¤±\n",
    "    \n",
    "    L_total = Î»_pixel * L_pixel + Î»_adv * L_adv\n",
    "    \n",
    "    Args:\n",
    "        lambda_pixel: åƒç´ æŸå¤±æƒé‡\n",
    "        lambda_adv: å¯¹æŠ—æŸå¤±æƒé‡\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda_pixel=1.0, lambda_adv=0.001, label_smoothing=0.1):\n",
    "        super(SRLoss, self).__init__()\n",
    "        self.lambda_pixel = lambda_pixel\n",
    "        self.lambda_adv = lambda_adv\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "        self.bce_loss = nn.BCELoss(reduction='mean')\n",
    "    \n",
    "    def pixel_loss(self, sr, hr):\n",
    "        \"\"\"åƒç´ çº§L1æŸå¤±\"\"\"\n",
    "        return self.l1_loss(sr, hr)\n",
    "    \n",
    "    def generator_loss(self, d_fake, sr, hr):\n",
    "        \"\"\"ç”Ÿæˆå™¨æ€»æŸå¤±\"\"\"\n",
    "        # åƒç´ æŸå¤±\n",
    "        pixel_loss = self.l1_loss(sr, hr) * self.lambda_pixel\n",
    "        \n",
    "        # å¯¹æŠ—æŸå¤±ï¼ˆç”Ÿæˆå™¨å¸Œæœ›åˆ¤åˆ«å™¨è¾“å‡ºæ¥è¿‘1ï¼‰\n",
    "        real_label = Tensor(1.0 - self.label_smoothing, mindspore.float32)\n",
    "        adv_loss = self.bce_loss(d_fake, ops.ones_like(d_fake) * real_label) * self.lambda_adv\n",
    "        \n",
    "        return pixel_loss + adv_loss, pixel_loss, adv_loss\n",
    "    \n",
    "    def discriminator_loss(self, d_real, d_fake):\n",
    "        \"\"\"åˆ¤åˆ«å™¨æŸå¤±\"\"\"\n",
    "        real_label = Tensor(1.0 - self.label_smoothing, mindspore.float32)\n",
    "        fake_label = Tensor(self.label_smoothing, mindspore.float32)\n",
    "        \n",
    "        real_loss = self.bce_loss(d_real, ops.ones_like(d_real) * real_label)\n",
    "        fake_loss = self.bce_loss(d_fake, ops.zeros_like(d_fake) + fake_label)\n",
    "        \n",
    "        return (real_loss + fake_loss) / 2\n",
    "\n",
    "print(\"âœ… æŸå¤±å‡½æ•°å®šä¹‰å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. è®­ç»ƒå¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒç½‘ç»œå°è£…\n",
    "from mindspore import save_checkpoint, load_checkpoint, load_param_into_net\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "\n",
    "# å‚æ•°å‘½åå‰ç¼€ï¼ˆé¿å…å†²çªï¼‰\n",
    "def rename_params(net, prefix):\n",
    "    for param in net.get_parameters():\n",
    "        param.name = f\"{prefix}_{param.name}\"\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"è®¡ç®—PSNRï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼‰\n",
    "    \n",
    "    Args:\n",
    "        img1, img2: uint8å›¾åƒï¼Œshapeä¸º(H, W, C)\n",
    "    Returns:\n",
    "        PSNRå€¼ï¼ˆdBï¼‰\n",
    "    \"\"\"\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    \"\"\"è®¡ç®—SSIMï¼ˆç»“æ„ç›¸ä¼¼æ€§ï¼‰\n",
    "    \n",
    "    Args:\n",
    "        img1, img2: uint8å›¾åƒï¼Œshapeä¸º(H, W, C)\n",
    "    Returns:\n",
    "        SSIMå€¼ï¼ˆ0-1ä¹‹é—´ï¼‰\n",
    "    \"\"\"\n",
    "    # è·å–å›¾åƒæœ€å°è¾¹é•¿ï¼ŒåŠ¨æ€è°ƒæ•´win_size\n",
    "    min_side = min(img1.shape[0], img1.shape[1])\n",
    "    # win_sizeå¿…é¡»æ˜¯å¥‡æ•°ä¸”ä¸è¶…è¿‡å›¾åƒæœ€å°è¾¹é•¿\n",
    "    win_size = min(7, min_side)\n",
    "    if win_size % 2 == 0:\n",
    "        win_size -= 1\n",
    "    if win_size < 3:\n",
    "        win_size = 3\n",
    "    return ssim(img1, img2, channel_axis=2, data_range=255, win_size=win_size)\n",
    "\n",
    "class SRTrainer:\n",
    "    \"\"\"è¶…åˆ†è¾¨ç‡è®­ç»ƒå™¨\"\"\"\n",
    "    def __init__(self, generator, discriminator, loss_fn, \n",
    "                 lr_g=1e-4, lr_d=1e-4, beta1=0.9):\n",
    "        self.G = generator\n",
    "        self.D = discriminator\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "        # é‡å‘½åå‚æ•°\n",
    "        rename_params(self.G, \"G\")\n",
    "        rename_params(self.D, \"D\")\n",
    "        \n",
    "        # ä¼˜åŒ–å™¨\n",
    "        self.opt_G = nn.Adam(self.G.trainable_params(), learning_rate=lr_g, beta1=beta1)\n",
    "        self.opt_D = nn.Adam(self.D.trainable_params(), learning_rate=lr_d, beta1=beta1)\n",
    "        \n",
    "        # æ¢¯åº¦å‡½æ•°\n",
    "        self.grad_G = ops.value_and_grad(self._g_loss, None, self.opt_G.parameters)\n",
    "        self.grad_D = ops.value_and_grad(self._d_loss, None, self.opt_D.parameters)\n",
    "    \n",
    "    def _g_loss(self, lr, hr):\n",
    "        \"\"\"ç”Ÿæˆå™¨å‰å‘ + æŸå¤±\"\"\"\n",
    "        sr = self.G(lr)\n",
    "        d_fake = self.D(sr)\n",
    "        total_loss, pixel_loss, adv_loss = self.loss_fn.generator_loss(d_fake, sr, hr)\n",
    "        return total_loss\n",
    "    \n",
    "    def _d_loss(self, lr, hr):\n",
    "        \"\"\"åˆ¤åˆ«å™¨å‰å‘ + æŸå¤±\"\"\"\n",
    "        sr = self.G(lr)\n",
    "        sr = ops.stop_gradient(sr)  # ä¸è®¡ç®—ç”Ÿæˆå™¨æ¢¯åº¦\n",
    "        d_real = self.D(hr)\n",
    "        d_fake = self.D(sr)\n",
    "        return self.loss_fn.discriminator_loss(d_real, d_fake)\n",
    "    \n",
    "    def train_step(self, lr, hr):\n",
    "        \"\"\"å•æ­¥è®­ç»ƒ\"\"\"\n",
    "        # è®­ç»ƒç”Ÿæˆå™¨\n",
    "        g_loss, g_grads = self.grad_G(lr, hr)\n",
    "        self.opt_G(g_grads)\n",
    "        \n",
    "        # è®­ç»ƒåˆ¤åˆ«å™¨\n",
    "        d_loss, d_grads = self.grad_D(lr, hr)\n",
    "        self.opt_D(d_grads)\n",
    "        \n",
    "        return g_loss, d_loss\n",
    "    \n",
    "    def generate(self, lr):\n",
    "        \"\"\"ç”ŸæˆSRå›¾åƒ\"\"\"\n",
    "        self.G.set_train(False)\n",
    "        sr = self.G(lr)\n",
    "        self.G.set_train(True)\n",
    "        return sr\n",
    "\n",
    "print(\"âœ… è®­ç»ƒå™¨å®šä¹‰å®Œæˆï¼\")\n",
    "print(\"âœ… PSNR/SSIMè®¡ç®—å‡½æ•°å®šä¹‰å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸»è®­ç»ƒå¾ªç¯é…ç½®\n",
    "import os\n",
    "\n",
    "# ===================== ä¸¤é˜¶æ®µè®­ç»ƒé…ç½®è¯´æ˜ =====================\n",
    "# ã€æ–¹æ¡ˆäºŒï¼šä¸¤é˜¶æ®µå®Œæ•´è®­ç»ƒã€‘\n",
    "# \n",
    "# ç¬¬ä¸€é˜¶æ®µï¼ˆåƒç´ çº§é¢„è®­ç»ƒï¼‰ï¼š\n",
    "#   - LAMBDA_ADV = 0.0ï¼ˆçº¯L1æŸå¤±ï¼‰\n",
    "#   - EPOCHS = 600, LR_G = 2e-4\n",
    "#   - n_residual = 23ï¼ˆå¢åŠ æ¨¡å‹å®¹é‡ï¼Œæ›´å¥½åˆ©ç”¨GPUï¼‰\n",
    "#   - é¢„æœŸPSNR: 25~27dB\n",
    "#\n",
    "# ç¬¬äºŒé˜¶æ®µï¼ˆGANç²¾è°ƒï¼‰- å®Œæˆç¬¬ä¸€é˜¶æ®µåå–æ¶ˆæ³¨é‡Šå¹¶ä½¿ç”¨\n",
    "# ============================================================\n",
    "\n",
    "# ==================== ç¬¬ä¸€é˜¶æ®µé…ç½® ====================\n",
    "# EPOCHS = 600              # è®­ç»ƒè½®æ•°\n",
    "# LR_G = 2e-4               # ç”Ÿæˆå™¨å­¦ä¹ ç‡\n",
    "# LR_D = 1e-4               # åˆ¤åˆ«å™¨å­¦ä¹ ç‡ï¼ˆæœªä½¿ç”¨ï¼‰\n",
    "# LAMBDA_PIXEL = 1.0        # åƒç´ æŸå¤±æƒé‡\n",
    "# LAMBDA_ADV = 0.0          # å¯¹æŠ—æŸå¤±æƒé‡ï¼ˆç¬¬ä¸€é˜¶æ®µè®¾ä¸º0ï¼‰\n",
    "# SAVE_DIR = \"./ckpt_sr\"    # æ¨¡å‹ä¿å­˜ç›®å½•\n",
    "# EVAL_INTERVAL = 25        # è¯„ä¼°é—´éš”\n",
    "# N_RESIDUAL = 23           # æ®‹å·®å—æ•°é‡\n",
    "# N_FEATURES = 64           # ç‰¹å¾é€šé“æ•°\n",
    "# LR_DECAY = True\n",
    "# LR_DECAY_EPOCHS = [300, 450, 550]\n",
    "# LR_DECAY_FACTOR = 0.5\n",
    "# PRETRAINED_G = None\n",
    "# PRETRAINED_D = None\n",
    "# ================================================================\n",
    "\n",
    "# ==================== ç¬¬äºŒé˜¶æ®µé…ç½®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ ====================\n",
    "# ä¼˜åŒ–ç‚¹ï¼š\n",
    "# 1. LAMBDA_ADV: 0.001 -> 0.005ï¼ˆå¢å¼ºGANæ•ˆæœï¼Œæå‡çº¹ç†ç»†èŠ‚ï¼‰\n",
    "# 2. LR_D: 2e-5 -> 5e-5ï¼ˆä¸LR_Gä¿æŒä¸€è‡´ï¼Œç¡®ä¿Dè®­ç»ƒå……åˆ†ï¼‰\n",
    "# 3. PRETRAINED_D: æ”¯æŒä»æ£€æŸ¥ç‚¹æ¢å¤Dæ¨¡å‹\n",
    "EPOCHS = 200\n",
    "LR_G = 5e-5               # ç”Ÿæˆå™¨å­¦ä¹ ç‡ï¼ˆç²¾è°ƒç”¨å°å­¦ä¹ ç‡ï¼‰\n",
    "LR_D = 5e-5               # åˆ¤åˆ«å™¨å­¦ä¹ ç‡ï¼ˆä¸Gä¿æŒä¸€è‡´ï¼‰\n",
    "LAMBDA_PIXEL = 1.0        # åƒç´ æŸå¤±æƒé‡\n",
    "LAMBDA_ADV = 0.005        # å¯¹æŠ—æŸå¤±æƒé‡ï¼ˆä¼˜åŒ–ï¼š0.001->0.005ï¼‰\n",
    "SAVE_DIR = \"./ckpt_sr_stage2\"\n",
    "EVAL_INTERVAL = 20\n",
    "N_RESIDUAL = 23           # å¿…é¡»ä¸ç¬¬ä¸€é˜¶æ®µä¸€è‡´\n",
    "N_FEATURES = 64           # å¿…é¡»ä¸ç¬¬ä¸€é˜¶æ®µä¸€è‡´\n",
    "LR_DECAY = True\n",
    "LR_DECAY_EPOCHS = [100, 150, 180]\n",
    "LR_DECAY_FACTOR = 0.5\n",
    "PRETRAINED_G = \"./ckpt_sr/G_best.ckpt\"  # åŠ è½½ç¬¬ä¸€é˜¶æ®µæœ€ä½³æ¨¡å‹\n",
    "PRETRAINED_D = None  # é¦–æ¬¡GANè®­ç»ƒè®¾ä¸ºNoneï¼Œæ¢å¤è®­ç»ƒæ—¶è®¾ä¸º \"./ckpt_sr_stage2/D_best.ckpt\"\n",
    "# ================================================================\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "print(\"=\" * 60)\n",
    "print(\"åˆå§‹åŒ–æ¨¡å‹...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G = SRResNet(scale=SCALE, n_residual=N_RESIDUAL, n_features=N_FEATURES)\n",
    "D = Discriminator(in_channels=3, ndf=64)\n",
    "\n",
    "# é‡å‘½åå‚æ•°ï¼ˆå¿…é¡»åœ¨åŠ è½½æƒé‡ä¹‹å‰ï¼‰\n",
    "rename_params(G, \"G\")\n",
    "rename_params(D, \"D\")\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆç¬¬äºŒé˜¶æ®µä½¿ç”¨ï¼‰\n",
    "if PRETRAINED_G is not None and os.path.exists(PRETRAINED_G):\n",
    "    param_dict = load_checkpoint(PRETRAINED_G)\n",
    "    load_param_into_net(G, param_dict)\n",
    "    print(f\"âœ… å·²åŠ è½½ç”Ÿæˆå™¨é¢„è®­ç»ƒæƒé‡: {PRETRAINED_G}\")\n",
    "\n",
    "if PRETRAINED_D is not None and os.path.exists(PRETRAINED_D):\n",
    "    param_dict = load_checkpoint(PRETRAINED_D)\n",
    "    load_param_into_net(D, param_dict)\n",
    "    print(f\"âœ… å·²åŠ è½½åˆ¤åˆ«å™¨é¢„è®­ç»ƒæƒé‡: {PRETRAINED_D}\")\n",
    "\n",
    "# ç»Ÿè®¡å‚æ•°é‡\n",
    "g_params = sum(p.size for p in G.get_parameters()) / 1e6\n",
    "d_params = sum(p.size for p in D.get_parameters()) / 1e6\n",
    "print(f\"ç”Ÿæˆå™¨å‚æ•°é‡: {g_params:.2f}M\")\n",
    "print(f\"åˆ¤åˆ«å™¨å‚æ•°é‡: {d_params:.2f}M\")\n",
    "\n",
    "# è®­ç»ƒå½¢å¼\n",
    "print(f\"\\nè®­ç»ƒå½¢å¼: {'GAN (å¯¹æŠ—è®­ç»ƒ)' if LAMBDA_ADV > 0 else 'çº¯åƒç´ æŸå¤±'}\")\n",
    "print(f\"æ¨¡å‹é…ç½®: n_residual={N_RESIDUAL}, n_features={N_FEATURES}\")\n",
    "print(f\"LR shape: (1, 3, {LR_SIZE}, {LR_SIZE})\")\n",
    "\n",
    "# åˆ›å»ºæŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "loss_fn = SRLoss(lambda_pixel=LAMBDA_PIXEL, lambda_adv=LAMBDA_ADV)\n",
    "optimizer_G = nn.Adam(G.trainable_params(), learning_rate=LR_G, beta1=0.9)\n",
    "optimizer_D = nn.Adam(D.trainable_params(), learning_rate=LR_D, beta1=0.9)\n",
    "\n",
    "print(f\"\\n=== å¼€å§‹è®­ç»ƒ (å…± {EPOCHS} è½®) ===\")\n",
    "print(f\"é…ç½®: LR_G={LR_G}, LR_D={LR_D}, Î»_pixel={LAMBDA_PIXEL}, Î»_adv={LAMBDA_ADV}\")\n",
    "if LR_DECAY:\n",
    "    print(f\"å­¦ä¹ ç‡è¡°å‡: åœ¨ç¬¬{LR_DECAY_EPOCHS}è½®ï¼Œè¡°å‡å› å­={LR_DECAY_FACTOR}\")\n",
    "\n",
    "# å®šä¹‰è®­ç»ƒæ­¥éª¤\n",
    "def _g_loss(lr, hr):\n",
    "    sr = G(lr)\n",
    "    d_fake = D(sr)\n",
    "    total_loss, pixel_loss, adv_loss = loss_fn.generator_loss(d_fake, sr, hr)\n",
    "    return total_loss\n",
    "\n",
    "def _d_loss(lr, hr):\n",
    "    sr = G(lr)\n",
    "    sr = ops.stop_gradient(sr)\n",
    "    d_real = D(hr)\n",
    "    d_fake = D(sr)\n",
    "    return loss_fn.discriminator_loss(d_real, d_fake)\n",
    "\n",
    "def _pixel_loss(lr, hr):\n",
    "    sr = G(lr)\n",
    "    return loss_fn.pixel_loss(sr, hr)\n",
    "\n",
    "grad_G = ops.value_and_grad(_g_loss, None, optimizer_G.parameters)\n",
    "grad_D = ops.value_and_grad(_d_loss, None, optimizer_D.parameters)\n",
    "grad_pixel = ops.value_and_grad(_pixel_loss, None, optimizer_G.parameters)\n",
    "\n",
    "def train_step_gan(lr, hr):\n",
    "    \"\"\"GANè®­ç»ƒæ­¥éª¤\"\"\"\n",
    "    g_loss, g_grads = grad_G(lr, hr)\n",
    "    optimizer_G(g_grads)\n",
    "    d_loss, d_grads = grad_D(lr, hr)\n",
    "    optimizer_D(d_grads)\n",
    "    return g_loss, d_loss\n",
    "\n",
    "def train_step_pixel(lr, hr):\n",
    "    \"\"\"çº¯åƒç´ æŸå¤±è®­ç»ƒæ­¥éª¤\"\"\"\n",
    "    loss, grads = grad_pixel(lr, hr)\n",
    "    optimizer_G(grads)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå¾ªç¯\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®°å½•è®­ç»ƒå†å²\n",
    "history = {\n",
    "    'epoch': [],\n",
    "    'g_loss': [],\n",
    "    'd_loss': [],\n",
    "    'psnr': [],\n",
    "    'ssim': []\n",
    "}\n",
    "\n",
    "best_psnr = 0.0\n",
    "\n",
    "# è·å–å›ºå®šçš„éªŒè¯æ ·æœ¬ç”¨äºå¯è§†åŒ–\n",
    "fixed_sample = next(val_dataset.create_dict_iterator())\n",
    "fixed_lr = fixed_sample['lr']\n",
    "fixed_hr = fixed_sample['hr'].asnumpy()[0]\n",
    "\n",
    "print(f\"å¼€å§‹è®­ç»ƒ...\")\n",
    "print(f\"è®­ç»ƒé›†å¤§å°: {train_dataset.get_dataset_size()} batches\")\n",
    "print(f\"éªŒè¯é›†å¤§å°: {val_dataset.get_dataset_size()} batches\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    G.set_train(True)\n",
    "    if LAMBDA_ADV > 0:\n",
    "        D.set_train(True)\n",
    "    \n",
    "    epoch_g_loss = 0.0\n",
    "    epoch_d_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    # è®­ç»ƒè¿›åº¦æ¡\n",
    "    train_pbar = tqdm(train_dataset.create_dict_iterator(), \n",
    "                     total=train_dataset.get_dataset_size(),\n",
    "                     desc=f\"Epoch {epoch:3d}/{EPOCHS}\",\n",
    "                     leave=False)\n",
    "    \n",
    "    for batch in train_pbar:\n",
    "        hr = batch['hr']\n",
    "        lr = batch['lr']\n",
    "        \n",
    "        # GANè®­ç»ƒ\n",
    "        if LAMBDA_ADV > 0:\n",
    "            g_loss, d_loss = train_step_gan(lr, hr)\n",
    "            epoch_d_loss += d_loss.asnumpy()\n",
    "        else:\n",
    "            g_loss = train_step_pixel(lr, hr)\n",
    "        \n",
    "        epoch_g_loss += g_loss.asnumpy()\n",
    "        n_batches += 1\n",
    "        \n",
    "        # æ›´æ–°è¿›åº¦æ¡\n",
    "        if LAMBDA_ADV > 0:\n",
    "            train_pbar.set_postfix({\n",
    "                'G_loss': f\"{g_loss.asnumpy():.4f}\",\n",
    "                'D_loss': f\"{d_loss.asnumpy():.4f}\"\n",
    "            })\n",
    "        else:\n",
    "            train_pbar.set_postfix({'loss': f\"{g_loss.asnumpy():.4f}\"})\n",
    "    \n",
    "    avg_g_loss = epoch_g_loss / n_batches\n",
    "    avg_d_loss = epoch_d_loss / n_batches if LAMBDA_ADV > 0 else 0\n",
    "    \n",
    "    # å­¦ä¹ ç‡è¡°å‡\n",
    "    if LR_DECAY and epoch in LR_DECAY_EPOCHS:\n",
    "        current_lr_g = float(optimizer_G.learning_rate.data.asnumpy())\n",
    "        new_lr_g = current_lr_g * LR_DECAY_FACTOR\n",
    "        optimizer_G.learning_rate.set_data(Tensor(new_lr_g, mindspore.float32))\n",
    "        tqdm.write(f\"   ğŸ“‰ å­¦ä¹ ç‡è¡°å‡: G {current_lr_g:.2e} -> {new_lr_g:.2e}\")\n",
    "        \n",
    "        if LAMBDA_ADV > 0:\n",
    "            current_lr_d = float(optimizer_D.learning_rate.data.asnumpy())\n",
    "            new_lr_d = current_lr_d * LR_DECAY_FACTOR\n",
    "            optimizer_D.learning_rate.set_data(Tensor(new_lr_d, mindspore.float32))\n",
    "            tqdm.write(f\"   ğŸ“‰ å­¦ä¹ ç‡è¡°å‡: D {current_lr_d:.2e} -> {new_lr_d:.2e}\")\n",
    "    \n",
    "    # éªŒè¯\n",
    "    if epoch % EVAL_INTERVAL == 0 or epoch == EPOCHS:\n",
    "        G.set_train(False)\n",
    "        psnr_list = []\n",
    "        ssim_list = []\n",
    "        \n",
    "        for val_batch in val_dataset.create_dict_iterator():\n",
    "            val_lr = val_batch['lr']\n",
    "            val_hr = val_batch['hr']\n",
    "            \n",
    "            sr = G(val_lr)\n",
    "            \n",
    "            # è®¡ç®—æŒ‡æ ‡\n",
    "            sr_np = denormalize(sr.asnumpy()[0])\n",
    "            hr_np = denormalize(val_hr.asnumpy()[0])\n",
    "            \n",
    "            psnr_val = calculate_psnr(sr_np, hr_np)\n",
    "            ssim_val = calculate_ssim(sr_np, hr_np)\n",
    "            psnr_list.append(psnr_val)\n",
    "            ssim_list.append(ssim_val)\n",
    "        \n",
    "        avg_psnr = np.mean(psnr_list)\n",
    "        avg_ssim = np.mean(ssim_list)\n",
    "        \n",
    "        history['epoch'].append(epoch)\n",
    "        history['g_loss'].append(avg_g_loss)\n",
    "        history['d_loss'].append(avg_d_loss)\n",
    "        history['psnr'].append(avg_psnr)\n",
    "        history['ssim'].append(avg_ssim)\n",
    "        \n",
    "        # æ‰“å°æ—¥å¿—\n",
    "        if LAMBDA_ADV > 0:\n",
    "            tqdm.write(f\"\\nEpoch {epoch:3d}/{EPOCHS} | Loss: {avg_g_loss:.4f} | \"\n",
    "                  f\"PSNR: {avg_psnr:.2f}dB | SSIM: {avg_ssim:.4f} | \"\n",
    "                  f\"G_loss: {avg_g_loss:.4f} | D_loss: {avg_d_loss:.4f}\")\n",
    "        else:\n",
    "            tqdm.write(f\"\\nEpoch {epoch:3d}/{EPOCHS} | Loss: {avg_g_loss:.4f} | \"\n",
    "                  f\"PSNR: {avg_psnr:.2f}dB | SSIM: {avg_ssim:.4f}\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŒæ—¶ä¿å­˜Gå’ŒDï¼‰\n",
    "        if avg_psnr > best_psnr:\n",
    "            best_psnr = avg_psnr\n",
    "            save_checkpoint(G, os.path.join(SAVE_DIR, \"G_best.ckpt\"))\n",
    "            if LAMBDA_ADV > 0:\n",
    "                save_checkpoint(D, os.path.join(SAVE_DIR, \"D_best.ckpt\"))\n",
    "                tqdm.write(f\"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ G+D (PSNR: {best_psnr:.2f}dB)\")\n",
    "            else:\n",
    "                tqdm.write(f\"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (PSNR: {best_psnr:.2f}dB)\")\n",
    "        \n",
    "        if fixed_lr is not None:\n",
    "            G.set_train(False)\n",
    "            sr = G(fixed_lr).asnumpy()[0]\n",
    "            G.set_train(True)\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            lr_img = denormalize(fixed_lr.asnumpy()[0])\n",
    "            axes[0].imshow(lr_img)\n",
    "            axes[0].set_title(f'LR Input ({lr_img.shape[0]}x{lr_img.shape[1]})')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            sr_img = denormalize(sr)\n",
    "            axes[1].imshow(sr_img)\n",
    "            axes[1].set_title(f'SR Output ({sr_img.shape[0]}x{sr_img.shape[1]})')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            hr_img = denormalize(fixed_hr)\n",
    "            axes[2].imshow(hr_img)\n",
    "            axes[2].set_title(f'HR Ground Truth ({hr_img.shape[0]}x{hr_img.shape[1]})')\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            plt.suptitle(f'Epoch {epoch} - PSNR: {avg_psnr:.2f}dB, SSIM: {avg_ssim:.4f}', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(SAVE_DIR, f'result_epoch_{epoch}.png'), dpi=150)\n",
    "            plt.show()\n",
    "    \n",
    "    # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹\n",
    "    if epoch % EVAL_INTERVAL == 0:\n",
    "        save_checkpoint(G, os.path.join(SAVE_DIR, f\"G_epoch_{epoch}.ckpt\"))\n",
    "        if LAMBDA_ADV > 0:\n",
    "            save_checkpoint(D, os.path.join(SAVE_DIR, f\"D_epoch_{epoch}.ckpt\"))\n",
    "\n",
    "# ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "save_checkpoint(G, os.path.join(SAVE_DIR, \"G_final.ckpt\"))\n",
    "if LAMBDA_ADV > 0:\n",
    "    save_checkpoint(D, os.path.join(SAVE_DIR, \"D_final.ckpt\"))\n",
    "\n",
    "print(f\"\\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³PSNR: {best_psnr:.2f}dB\")\n",
    "print(f\"æ¨¡å‹ä¿å­˜åˆ°: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# æŸå¤±æ›²çº¿\n",
    "axes[0].plot(history['g_loss'], label='Generator Loss', color='blue')\n",
    "axes[0].plot(history['d_loss'], label='Discriminator Loss', color='red')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PSNRæ›²çº¿\n",
    "eval_epochs = list(range(EVAL_INTERVAL, len(history['psnr'])*EVAL_INTERVAL+1, EVAL_INTERVAL))\n",
    "if len(eval_epochs) > len(history['psnr']):\n",
    "    eval_epochs = eval_epochs[:len(history['psnr'])]\n",
    "axes[1].plot(eval_epochs, history['psnr'], marker='o', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('PSNR (dB)')\n",
    "axes[1].set_title('PSNR on Validation Set')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIMæ›²çº¿\n",
    "axes[2].plot(eval_epochs, history['ssim'], marker='s', color='orange')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('SSIM')\n",
    "axes[2].set_title('SSIM on Validation Set')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'training_curves.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. æ¨¡å‹è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°\n",
    "print(\"=== åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼° ===\")\n",
    "\n",
    "G_eval = SRResNet(scale=SCALE, n_residual=N_RESIDUAL, n_features=N_FEATURES)\n",
    "rename_params(G_eval, \"G\")\n",
    "\n",
    "ckpt_path = os.path.join(SAVE_DIR, \"G_best.ckpt\")\n",
    "if os.path.exists(ckpt_path):\n",
    "    param_dict = load_checkpoint(ckpt_path)\n",
    "    load_param_into_net(G_eval, param_dict)\n",
    "    print(f\"âœ… å·²åŠ è½½æ¨¡å‹: {ckpt_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼Œä½¿ç”¨å½“å‰æ¨¡å‹\")\n",
    "    G_eval = G\n",
    "\n",
    "G_eval.set_train(False)\n",
    "\n",
    "# åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°\n",
    "print(\"\\n[éªŒè¯é›†è¯„ä¼°]\")\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "\n",
    "for batch in val_dataset.create_dict_iterator():\n",
    "    hr = batch['hr'].asnumpy()\n",
    "    lr = batch['lr']\n",
    "    sr = G_eval(lr).asnumpy()\n",
    "    \n",
    "    for i in range(sr.shape[0]):\n",
    "        # ä¿®å¤ï¼šä½¿ç”¨ denormalize è½¬æ¢æ ¼å¼ (CHW, [-1,1]) -> (HWC, [0,255] uint8)\n",
    "        sr_img = denormalize(sr[i])\n",
    "        hr_img = denormalize(hr[i])\n",
    "        \n",
    "        p = calculate_psnr(sr_img, hr_img)\n",
    "        s = calculate_ssim(sr_img, hr_img)\n",
    "        psnr_list.append(p)\n",
    "        ssim_list.append(s)\n",
    "        print(f\"  æ ·æœ¬ {len(psnr_list)}: PSNR={p:.2f}dB, SSIM={s:.4f}\")\n",
    "\n",
    "print(f\"\\nå¹³å‡ PSNR: {np.mean(psnr_list):.2f}dB\")\n",
    "print(f\"å¹³å‡ SSIM: {np.mean(ssim_list):.4f}\")\n",
    "\n",
    "# éªŒæ”¶æ ‡å‡†åˆ¤æ–­\n",
    "print(\"\\n[éªŒæ”¶æ ‡å‡†æ£€æŸ¥]\")\n",
    "if np.mean(psnr_list) >= 28:\n",
    "    print(f\"âœ… PSNR â‰¥ 28dB (å®é™…: {np.mean(psnr_list):.2f}dB)\")\n",
    "else:\n",
    "    print(f\"âŒ PSNR < 28dB (å®é™…: {np.mean(psnr_list):.2f}dB)ï¼Œå»ºè®®å¢åŠ è®­ç»ƒè½®æ•°\")\n",
    "\n",
    "if np.mean(ssim_list) >= 0.80:\n",
    "    print(f\"âœ… SSIM â‰¥ 0.80 (å®é™…: {np.mean(ssim_list):.4f})\")\n",
    "else:\n",
    "    print(f\"âŒ SSIM < 0.80 (å®é™…: {np.mean(ssim_list):.4f})ï¼Œå»ºè®®è°ƒæ•´æŸå¤±æƒé‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. æ¨ç†ä¸å¯è§†åŒ–\n",
    "\n",
    "å¯¹çœŸå®æ—§ç…§ç‰‡è¿›è¡Œä¿®å¤å¢å¼º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ—§ç…§ç‰‡æ¨ç†ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ˜¾å­˜é‡Šæ”¾ + å¤§å›¾åˆ†å—å¤„ç†ï¼‰\n",
    "from PIL import Image\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# ====== å…³é”®ï¼šé‡Šæ”¾è®­ç»ƒå ç”¨çš„æ˜¾å­˜ ======\n",
    "print(\"=== é‡Šæ”¾è®­ç»ƒå ç”¨çš„æ˜¾å­˜ ===\")\n",
    "\n",
    "# åˆ é™¤è®­ç»ƒæ—¶çš„å¤§å¯¹è±¡\n",
    "vars_to_delete = ['G', 'D', 'trainer', 'train_dataset', 'val_dataset', \n",
    "                  'fixed_lr', 'fixed_hr', 'history']\n",
    "for var_name in vars_to_delete:\n",
    "    if var_name in dir():\n",
    "        try:\n",
    "            exec(f\"del {var_name}\")\n",
    "            print(f\"  å·²åˆ é™¤: {var_name}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# å¼ºåˆ¶Pythonåƒåœ¾å›æ”¶\n",
    "gc.collect()\n",
    "\n",
    "# MindSpore æ˜¾å­˜æ¸…ç†\n",
    "try:\n",
    "    from mindspore import context\n",
    "    # é‡ç½®è®¡ç®—å›¾ç¼“å­˜\n",
    "    context.set_context(reserve_class_name_in_scope=False)\n",
    "    print(\"âœ… æ˜¾å­˜æ¸…ç†å®Œæˆ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ æ˜¾å­˜æ¸…ç†è­¦å‘Š: {e}\")\n",
    "\n",
    "# ====== é…ç½® ======\n",
    "OLD_PHOTOS_DIR = os.path.join(DATA_ROOT, 'old_photos')\n",
    "OUTPUT_DIR = \"./output_sr\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# å¤§å›¾å¤„ç†å‚æ•°\n",
    "MAX_INPUT_SIZE = 256  # æœ€å¤§è¾“å…¥å°ºå¯¸ï¼ˆè¶…è¿‡åˆ™ç¼©æ”¾ï¼‰\n",
    "TILE_SIZE = 128       # åˆ†å—å¤§å°ï¼ˆæ˜¾å­˜ä¸è¶³æ—¶ä½¿ç”¨ï¼‰\n",
    "TILE_OVERLAP = 16     # åˆ†å—é‡å ï¼ˆé¿å…æ¥ç¼ï¼‰\n",
    "\n",
    "def inference_single_safe(model, image_path, scale=4, max_size=256):\n",
    "    \"\"\"å®‰å…¨çš„å•å¼ å›¾åƒæ¨ç†ï¼ˆæ”¯æŒå¤§å›¾ç¼©æ”¾ï¼‰\n",
    "    \n",
    "    Args:\n",
    "        model: ç”Ÿæˆå™¨æ¨¡å‹\n",
    "        image_path: å›¾åƒè·¯å¾„\n",
    "        scale: æ”¾å¤§å€æ•°\n",
    "        max_size: æœ€å¤§è¾“å…¥å°ºå¯¸ï¼Œè¶…è¿‡åˆ™å…ˆç¼©æ”¾\n",
    "    \"\"\"\n",
    "    # è¯»å–å›¾åƒ\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    original_size = img.size  # (W, H)\n",
    "    print(f\"   åŸå§‹å°ºå¯¸: {original_size[0]}x{original_size[1]}\")\n",
    "    \n",
    "    # å¦‚æœå›¾åƒå¤ªå¤§ï¼Œå…ˆç¼©æ”¾åˆ°max_size\n",
    "    w, h = original_size\n",
    "    if max(w, h) > max_size:\n",
    "        ratio = max_size / max(w, h)\n",
    "        new_w = int(w * ratio)\n",
    "        new_h = int(h * ratio)\n",
    "        img_input = img.resize((new_w, new_h), Image.BICUBIC)\n",
    "        print(f\"   ç¼©æ”¾è‡³: {new_w}x{new_h} (æ˜¾å­˜ä¼˜åŒ–)\")\n",
    "    else:\n",
    "        img_input = img\n",
    "    \n",
    "    # é¢„å¤„ç†\n",
    "    img_np = np.array(img_input).astype(np.float32) / 127.5 - 1.0\n",
    "    img_np = img_np.transpose(2, 0, 1)  # HWC -> CHW\n",
    "    img_tensor = Tensor(img_np[np.newaxis, ...], mindspore.float32)\n",
    "    \n",
    "    # æ¨ç†\n",
    "    model.set_train(False)\n",
    "    sr_tensor = model(img_tensor)\n",
    "    \n",
    "    # åå¤„ç†\n",
    "    sr_np = sr_tensor.asnumpy()[0]\n",
    "    sr_np = (sr_np * 127.5 + 127.5).clip(0, 255).astype(np.uint8)\n",
    "    sr_np = sr_np.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    sr_img = Image.fromarray(sr_np)\n",
    "    \n",
    "    return img, sr_img\n",
    "\n",
    "def inference_tiled(model, image_path, scale=4, tile_size=128, overlap=16):\n",
    "    \"\"\"åˆ†å—æ¨ç†ï¼ˆé€‚ç”¨äºè¶…å¤§å›¾åƒï¼‰\n",
    "    \n",
    "    å°†å¤§å›¾åˆ‡åˆ†æˆå°å—åˆ†åˆ«å¤„ç†ï¼Œæœ€åæ‹¼æ¥\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    original_size = img.size\n",
    "    w, h = original_size\n",
    "    print(f\"   åŸå§‹å°ºå¯¸: {w}x{h}\")\n",
    "    print(f\"   ä½¿ç”¨åˆ†å—å¤„ç†: tile={tile_size}, overlap={overlap}\")\n",
    "    \n",
    "    # è¾“å‡ºå›¾åƒå°ºå¯¸\n",
    "    out_w, out_h = w * scale, h * scale\n",
    "    sr_result = np.zeros((out_h, out_w, 3), dtype=np.float32)\n",
    "    sr_count = np.zeros((out_h, out_w, 1), dtype=np.float32)\n",
    "    \n",
    "    # åˆ†å—å¤„ç†\n",
    "    stride = tile_size - overlap\n",
    "    tiles_x = (w + stride - 1) // stride\n",
    "    tiles_y = (h + stride - 1) // stride\n",
    "    total_tiles = tiles_x * tiles_y\n",
    "    \n",
    "    tile_idx = 0\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            tile_idx += 1\n",
    "            # è®¡ç®—å®é™…tileåŒºåŸŸ\n",
    "            x1, y1 = x, y\n",
    "            x2 = min(x + tile_size, w)\n",
    "            y2 = min(y + tile_size, h)\n",
    "            \n",
    "            # è£å‰ªtile\n",
    "            tile = img.crop((x1, y1, x2, y2))\n",
    "            tile_w, tile_h = tile.size\n",
    "            \n",
    "            # é¢„å¤„ç†\n",
    "            tile_np = np.array(tile).astype(np.float32) / 127.5 - 1.0\n",
    "            tile_np = tile_np.transpose(2, 0, 1)\n",
    "            tile_tensor = Tensor(tile_np[np.newaxis, ...], mindspore.float32)\n",
    "            \n",
    "            # æ¨ç†\n",
    "            model.set_train(False)\n",
    "            sr_tile = model(tile_tensor).asnumpy()[0]\n",
    "            sr_tile = sr_tile.transpose(1, 2, 0)  # CHW -> HWC\n",
    "            \n",
    "            # æ”¾ç½®åˆ°è¾“å‡ºä½ç½®\n",
    "            ox1, oy1 = x1 * scale, y1 * scale\n",
    "            ox2, oy2 = ox1 + tile_w * scale, oy1 + tile_h * scale\n",
    "            \n",
    "            sr_result[oy1:oy2, ox1:ox2] += sr_tile\n",
    "            sr_count[oy1:oy2, ox1:ox2] += 1\n",
    "            \n",
    "            if tile_idx % 10 == 0:\n",
    "                print(f\"   è¿›åº¦: {tile_idx}/{total_tiles}\")\n",
    "    \n",
    "    # å¹³å‡é‡å åŒºåŸŸ\n",
    "    sr_result = sr_result / np.maximum(sr_count, 1)\n",
    "    sr_result = (sr_result * 127.5 + 127.5).clip(0, 255).astype(np.uint8)\n",
    "    sr_img = Image.fromarray(sr_result)\n",
    "    \n",
    "    return img, sr_img\n",
    "\n",
    "# ====== é‡æ–°åŠ è½½æ¨ç†æ¨¡å‹ï¼ˆè½»é‡çº§ï¼‰ ======\n",
    "print(\"\\n=== é‡æ–°åŠ è½½æ¨ç†æ¨¡å‹ ===\")\n",
    "G_eval = SRResNet(scale=SCALE, n_residual=16, n_features=64)\n",
    "rename_params(G_eval, \"G\")\n",
    "\n",
    "ckpt_path = os.path.join(SAVE_DIR, \"G_best.ckpt\")\n",
    "if os.path.exists(ckpt_path):\n",
    "    param_dict = load_checkpoint(ckpt_path)\n",
    "    load_param_into_net(G_eval, param_dict)\n",
    "    print(f\"âœ… å·²åŠ è½½æ¨¡å‹: {ckpt_path}\")\n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ°æ¨¡å‹: {ckpt_path}\")\n",
    "    raise FileNotFoundError(f\"è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {ckpt_path}\")\n",
    "\n",
    "G_eval.set_train(False)\n",
    "\n",
    "# ====== å¤„ç†æ‰€æœ‰æ—§ç…§ç‰‡ ======\n",
    "print(\"\\n=== æ—§ç…§ç‰‡ä¿®å¤æ¨ç† ===\")\n",
    "old_photos = [f for f in os.listdir(OLD_PHOTOS_DIR) if f.lower().endswith(IMAGE_EXTENSIONS)]\n",
    "print(f\"æ‰¾åˆ° {len(old_photos)} å¼ æ—§ç…§ç‰‡\")\n",
    "\n",
    "for photo_name in old_photos:\n",
    "    photo_path = os.path.join(OLD_PHOTOS_DIR, photo_name)\n",
    "    print(f\"\\nå¤„ç†: {photo_name}\")\n",
    "    \n",
    "    try:\n",
    "        # æ£€æŸ¥å›¾åƒå°ºå¯¸å†³å®šå¤„ç†æ–¹å¼\n",
    "        with Image.open(photo_path) as tmp_img:\n",
    "            w, h = tmp_img.size\n",
    "        \n",
    "        if max(w, h) > 512:\n",
    "            # è¶…å¤§å›¾ï¼šä½¿ç”¨åˆ†å—å¤„ç†\n",
    "            print(f\"   [åˆ†å—æ¨¡å¼] å›¾åƒè¾ƒå¤§ ({w}x{h})\")\n",
    "            original, restored = inference_tiled(G_eval, photo_path, SCALE, \n",
    "                                                  tile_size=TILE_SIZE, overlap=TILE_OVERLAP)\n",
    "        elif max(w, h) > MAX_INPUT_SIZE:\n",
    "            # å¤§å›¾ï¼šç¼©æ”¾åå¤„ç†\n",
    "            print(f\"   [ç¼©æ”¾æ¨¡å¼] å›¾åƒä¸­ç­‰ ({w}x{h})\")\n",
    "            original, restored = inference_single_safe(G_eval, photo_path, SCALE, MAX_INPUT_SIZE)\n",
    "        else:\n",
    "            # å°å›¾ï¼šç›´æ¥å¤„ç†\n",
    "            print(f\"   [ç›´æ¥æ¨¡å¼] å›¾åƒè¾ƒå° ({w}x{h})\")\n",
    "            original, restored = inference_single_safe(G_eval, photo_path, SCALE, max_size=w)\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        stem = os.path.splitext(photo_name)[0]\n",
    "        restored.save(os.path.join(OUTPUT_DIR, f\"{stem}_restored.png\"))\n",
    "        \n",
    "        # å¯è§†åŒ–å¯¹æ¯”\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "        \n",
    "        axes[0].imshow(original)\n",
    "        axes[0].set_title(f'Original ({original.size[0]}x{original.size[1]})', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(restored)\n",
    "        axes[1].set_title(f'Restored ({restored.size[0]}x{restored.size[1]})', fontsize=12)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Old Photo Restoration: {photo_name}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, f\"{stem}_comparison.png\"), dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"   âœ… ä¿å­˜åˆ°: {OUTPUT_DIR}/{stem}_restored.png\")\n",
    "        \n",
    "        # æ¯å¼ å›¾åæ¸…ç†ä¸€æ¬¡\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nğŸ‰ æ¨ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. é¡¹ç›®æ€»ç»“\n",
    "\n",
    "### å®Œæˆå†…å®¹\n",
    "1. âœ… ç¯å¢ƒæ­å»ºä¸éªŒè¯ï¼ˆMindSpore 2.2.14ï¼‰\n",
    "2. âœ… æ•°æ®é›†åŠ è½½ï¼ˆLR/HRé…å¯¹ï¼Œæ”¯æŒéšæœºè£å‰ªå’Œå¢å¼ºï¼‰\n",
    "3. âœ… SRResNetåŸºçº¿ç”Ÿæˆå™¨ï¼ˆ16æ®‹å·®å— + PixelShuffleä¸Šé‡‡æ ·ï¼‰\n",
    "4. âœ… ESRGANåˆ¤åˆ«å™¨ï¼ˆVGGé£æ ¼ï¼‰\n",
    "5. âœ… æŸå¤±å‡½æ•°ï¼ˆåƒç´ L1 + å¯¹æŠ—æŸå¤±ï¼‰\n",
    "6. âœ… è®­ç»ƒå¾ªç¯ï¼ˆæ”¯æŒPSNR/SSIMè¯„ä¼°ï¼‰\n",
    "7. âœ… æ¨¡å‹ä¿å­˜ä¸åŠ è½½\n",
    "8. âœ… æ—§ç…§ç‰‡æ¨ç†ä¸å¯è§†åŒ–\n",
    "\n",
    "### è¯„ä¼°æŒ‡æ ‡\n",
    "- PSNR: è¶Šé«˜è¶Šå¥½ï¼ˆç›®æ ‡ â‰¥28dBï¼‰\n",
    "- SSIM: è¶Šé«˜è¶Šå¥½ï¼ˆç›®æ ‡ â‰¥0.80ï¼‰\n",
    "\n",
    "### ä¼˜åŒ–å»ºè®®\n",
    "1. å¢åŠ è®­ç»ƒæ•°æ®é‡ï¼ˆæ¨è â‰¥800å¯¹ï¼‰\n",
    "2. æ·»åŠ æ„ŸçŸ¥æŸå¤±ï¼ˆVGGç‰¹å¾ï¼‰\n",
    "3. ä½¿ç”¨RRDBæ›¿ä»£ResBlockï¼ˆESRGANï¼‰\n",
    "4. æ•°æ®å¢å¼ºï¼šæ—‹è½¬ã€ç¼©æ”¾ã€é¢œè‰²æŠ–åŠ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"é«˜åˆ†è¾¨ç‡å›¾åƒä¿®å¤ä¸å¢å¼ºé¡¹ç›® - å®Œæˆ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\næ¨¡å‹ä¿å­˜è·¯å¾„: {SAVE_DIR}\")\n",
    "print(f\"æ¨ç†ç»“æœè·¯å¾„: {OUTPUT_DIR}\")\n",
    "print(\"\\né¡¹ç›®æ–‡ä»¶:\")\n",
    "print(\"  - G_best.ckpt: æœ€ä½³ç”Ÿæˆå™¨æƒé‡\")\n",
    "print(\"  - G_final.ckpt: æœ€ç»ˆç”Ÿæˆå™¨æƒé‡\")\n",
    "print(\"  - training_curves.png: è®­ç»ƒæ›²çº¿\")\n",
    "print(\"  - result_epoch_*.png: å„è½®ç»“æœ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
