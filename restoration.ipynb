{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高分辨率图像修复与增强（SR/Restoration GAN）\n",
    "\n",
    "基于 MindSpore 框架实现图像超分辨率重建与修复\n",
    "项目目标\n",
    "- 低清图像的超分辨率重建（LR→HR，×4放大）\n",
    "- 去噪、去模糊、去压缩伪影\n",
    "- 真实旧照片修复与增强\n",
    "\n",
    "技术路线\n",
    "- **基线模型**：SRResNet（像素损失训练，稳定易训）\n",
    "- **进阶模型**：ESRGAN（RRDBNet + RaGAN + 感知损失，感知质量更好）\n",
    "\n",
    "评估指标\n",
    "- 有GT：PSNR↑、SSIM↑\n",
    "- 无GT：主观评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 安装模块依赖\n",
    "\n",
    "#### 先自行创建一个python3.9的虚拟环境，并在此环境下安装依赖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装python依赖包（建议在终端下载依赖，后续操作用到哪个装哪个，不要一次性全部安装，会出现依赖版本冲突）\n",
    "# pip install opencv-python Pillow matplotlib scikit-image tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 MindSpore 2.2.14（CPU版） 安装命令\n",
    "#### 从官网下载安装wheel包进行安装，避免使用pip直接安装导致的依赖冲突问题\n",
    "\n",
    "选择对应的操作系统和python版本(当前文档使用的版本为windos的CPU版mindspore): mindspore-2.2.14-cp39-cp39-win_amd64.whl\n",
    "\n",
    "下载完whell包之后将.whl文件放到项目根目录下。\n",
    "\n",
    "随后执行以下命令(后续所有的终端命令请自行复制到终端运行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装 MindSpore（适用于 Windows 和 Python 3.9）\n",
    "# python -m pip install mindspore-2.2.14-cp39-cp39-win_amd64.whl --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 MindSpore 2.2.14（GPU版） 安装命令，适用于CUDA 11.6 \n",
    "GPU版详细安装命令请参考官网：https://gitee.com/mindspore/docs/blob/r2.2/install/mindspore_gpu_install_pip.md\n",
    "\n",
    "GPU版本安装前需要先安装对应版本的CUDA和CUDNN，建议参考官网说明进行安装，或者使用以下命令安装（不会安装可以直接询问AI）\n",
    "\n",
    "若未安装CUDA11.6和cuDNN8.5.0，请先使用以下命令安装(请复制到终端安装)\n",
    "\n",
    "PS：Mindspore GPU版本只适用于Linux系统，本文档环境为 Ubuntu 20.04系统（云服务器）\n",
    "\n",
    "需要使用云服务器可以选择AutoDL，如何使用建议参考B站视频：https://www.bilibili.com/video/BV1xDCbYCEZo/?spm_id_from=333.337.search-card.all.click&vd_source=b424755df5875d2c243ba347d8c91dcb\n",
    "\n",
    "云服务器默认提供了CUDA11.6和cuDNN8.5.0，无需重复安装，直接执行mindspore安装命令即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 云服务器默认提供CUDA 11.6，无需额外安装，若当前云服务器未提供CUDA 11.6，可参考以下步骤安装\n",
    "# 安装CUDA 11.6\n",
    "# 1. 下载CUDA 11.6的deb安装包（约3GB，确保网络通畅）\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/11.6.0/local_installers/cuda-repo-ubuntu2004-11-6-local_11.6.0-510.39.01-1_amd64.deb\n",
    "\n",
    "# 2. 安装deb包并导入公钥\n",
    "# sudo dpkg -i cuda-repo-ubuntu2004-11-6-local_11.6.0-510.39.01-1_amd64.deb\n",
    "# sudo cp /var/cuda-repo-ubuntu2004-11-6-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "\n",
    "# 3. 更新软件源并安装CUDA 11.6（包含驱动，若已装兼容驱动可跳过驱动安装）\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install -y cuda-toolkit-11-6  # 仅安装CUDA工具包（推荐）\n",
    "\n",
    "# 编辑用户环境变量文件（bash用户用.bashrc，zsh用户用.zshrc）\n",
    "# nano ~/.bashrc\n",
    "\n",
    "# 在文件末尾添加以下3行（复制粘贴）\n",
    "# export PATH=/usr/local/cuda-11.6/bin:$PATH\n",
    "# export LD_LIBRARY_PATH=/usr/local/cuda-11.6/lib64:$LD_LIBRARY_PATH\n",
    "# export CUDA_HOME=/usr/local/cuda-11.6\n",
    "\n",
    "# 保存生效（按 Ctrl+O 保存，Ctrl+X 退出nano）\n",
    "# source ~/.bashrc\n",
    "\n",
    "# 查看CUDA版本（应输出11.6）\n",
    "# nvcc -V  # 注意是大写V\n",
    "\n",
    "# 安装cuDNN 8.5.0\n",
    "# 访问 NVIDIA 官网下载页：https://developer.nvidia.com/cudnn-archive\n",
    "# 找到 Download cuDNN v8.5.0 (August 8th, 2022), for CUDA 11.x\n",
    "\n",
    "# 下载 Local Installer for Linux x86_64 (Tar)到本地后续上传到Linux服务器，假设文件名为cudnn-linux-x86_64-8.5.0.96_cuda11-archive.tar.xz\n",
    "# tar -xJvf cudnn-linux-x86_64-8.5.0.96_cuda11-archive.tar.xz\n",
    "# 进入解压后的cuDNN目录（替换为你实际的解压目录名）\n",
    "# cd cudnn-linux-x86_64-8.5.0.96_cuda11-archive\n",
    "\n",
    "# 复制头文件到CUDA的include目录\n",
    "# sudo cp include/cudnn*.h /usr/local/cuda-11.6/include/\n",
    "\n",
    "# 复制库文件到CUDA的lib64目录（-P保留符号链接）\n",
    "# sudo cp lib64/libcudnn* /usr/local/cuda-11.6/lib64/\n",
    "\n",
    "# 给复制的文件添加全局读取权限，避免后续程序无法调用 cuDNN\n",
    "# sudo chmod a+r /usr/local/cuda-11.6/include/cudnn*.h /usr/local/cuda-11.6/lib64/libcudnn*\n",
    "\n",
    "# 更新动态链接库缓存\n",
    "# sudo ldconfig /usr/local/cuda-11.6/lib64\n",
    "\n",
    "# 查看cuDNN的版本（从头文件中读取）\n",
    "# cat /usr/local/cuda-11.6/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n",
    "\n",
    "# 若输出类似以下内容，说明安装成功：\n",
    "#define CUDNN_MAJOR 8\n",
    "#define CUDNN_MINOR 5\n",
    "#define CUDNN_PATCHLEVEL 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载MindSpore 2.2.14 whl包\n",
    "# wget https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.2.14/MindSpore/unified/x86_64/mindspore-2.2.14-cp39-cp39-linux_x86_64.whl\n",
    "\n",
    "# 安装MindSpore\n",
    "# pip install mindspore-2.2.14-cp39-cp39-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 环境搭建与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境验证与GPU诊断\n",
    "import mindspore\n",
    "from mindspore import context\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MindSpore环境诊断 - 图像修复与增强项目\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. MindSpore版本信息\n",
    "print(f\"\\n[MindSpore信息]\")\n",
    "print(f\"   版本: {mindspore.__version__}\")\n",
    "print(f\"   安装路径: {mindspore.__file__}\")\n",
    "\n",
    "# 2. 检查CUDA环境\n",
    "print(f\"\\n[CUDA环境检查]\")\n",
    "cuda_available = False\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ NVIDIA驱动已安装\")\n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'CUDA Version' in line or 'GeForce' in line or 'RTX' in line:\n",
    "                print(f\"   {line.strip()}\")\n",
    "        cuda_available = True\n",
    "    else:\n",
    "        print(\"❌ NVIDIA驱动未找到\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 无法检测NVIDIA驱动: {e}\")\n",
    "\n",
    "# 3. MindSpore设备支持检查\n",
    "print(f\"\\n[MindSpore设备支持]\")\n",
    "gpu_supported = False\n",
    "try:\n",
    "    context.set_context(device_target=\"GPU\")\n",
    "    print(f\"✅ MindSpore支持GPU\")\n",
    "    gpu_supported = True\n",
    "except Exception as e:\n",
    "    print(f\"❌ MindSpore不支持GPU，使用CPU模式\")\n",
    "    context.set_context(device_target=\"CPU\")\n",
    "\n",
    "# 4. 当前设备状态\n",
    "print(f\"\\n[当前设备状态]\")\n",
    "current_device = context.get_context('device_target')\n",
    "print(f\"   使用设备: {current_device}\")\n",
    "\n",
    "# 5. 总结\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"诊断总结\")\n",
    "print(\"=\" * 60)\n",
    "if gpu_supported and cuda_available:\n",
    "    print(\"✅ GPU环境完整，可以使用GPU加速训练\")\n",
    "else:\n",
    "    print(\"ℹ️  当前环境使用CPU模式（训练速度较慢但功能完整）\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 数据集加载与预处理\n",
    "\n",
    "数据目录结构：\n",
    "```\n",
    "./data/\n",
    "  train_HR/    # 训练高分辨率图像（Ground Truth）\n",
    "  train_LR/    # 训练低分辨率/劣化图像（与HR配对）\n",
    "  val_HR/      # 验证高分辨率图像\n",
    "  val_LR/      # 验证低分辨率图像\n",
    "  old_photos/  # 真实旧照片（无GT，用于推理展示）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集统计与检查\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 配置\n",
    "DATA_ROOT = \"./data\"\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "def count_images(directory):\n",
    "    \"\"\"统计目录下的图片数量\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0, []\n",
    "    files = [f for f in os.listdir(directory) \n",
    "             if f.lower().endswith(IMAGE_EXTENSIONS) and os.path.isfile(os.path.join(directory, f))]\n",
    "    return len(files), sorted(files)\n",
    "\n",
    "# 统计各数据集\n",
    "print(\"=\" * 60)\n",
    "print(\"数据集统计\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "datasets = {\n",
    "    'train_HR': os.path.join(DATA_ROOT, 'train_HR'),\n",
    "    'train_LR': os.path.join(DATA_ROOT, 'train_LR'),\n",
    "    'val_HR': os.path.join(DATA_ROOT, 'val_HR'),\n",
    "    'val_LR': os.path.join(DATA_ROOT, 'val_LR'),\n",
    "    'old_photos': os.path.join(DATA_ROOT, 'old_photos')\n",
    "}\n",
    "\n",
    "for name, path in datasets.items():\n",
    "    count, files = count_images(path)\n",
    "    print(f\"{name}: {count} 张图像\")\n",
    "    if count > 0:\n",
    "        print(f\"   示例: {files[:3]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 成对数据集加载器\n",
    "import os\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.vision as vision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 配置参数\n",
    "DATA_ROOT = \"./data\"\n",
    "SCALE = 4  # 超分辨率放大倍数\n",
    "HR_SIZE = 128  # HR patch尺寸（训练时使用patch）\n",
    "LR_SIZE = HR_SIZE // SCALE  # LR patch尺寸\n",
    "BATCH_SIZE = 96  # 批大小（需小于数据量，否则会报错） #######（可调）\n",
    "NUM_WORKERS = 4  # 数据加载并行进程数\n",
    "MAX_TRAIN_SAMPLES = None  # 训练集最大加载数量，None表示加载全部 #######（可调）\n",
    "MAX_VAL_SAMPLES = None    # 验证集最大加载数量，None表示加载全部 #######（可调）\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def get_paired_paths(hr_dir, lr_dir, scale=4, max_samples=None):\n",
    "    \"\"\"获取配对的HR/LR图像路径\n",
    "    \n",
    "    支持处理文件名中包含空格的情况\n",
    "    HR文件名格式：{stem}.{ext}（可能包含空格）\n",
    "    LR文件名格式：{stem}x{scale}.png 或 {stem} x{scale}.png\n",
    "    \n",
    "    Args:\n",
    "        hr_dir: HR图像目录\n",
    "        lr_dir: LR图像目录\n",
    "        scale: 放大倍数\n",
    "        max_samples: 最大加载数量，None表示加载全部\n",
    "    \"\"\"\n",
    "    hr_files = sorted([f for f in os.listdir(hr_dir) if f.lower().endswith(IMAGE_EXTENSIONS)])\n",
    "    lr_files = os.listdir(lr_dir)\n",
    "    paired = []\n",
    "    \n",
    "    for hr_name in hr_files:\n",
    "        stem, ext = os.path.splitext(hr_name)\n",
    "        hr_path = os.path.join(hr_dir, hr_name)\n",
    "        \n",
    "        # 尝试多种LR文件名格式\n",
    "        lr_candidates = [\n",
    "            f\"{stem}x{scale}.png\",           # 标准格式：0003x4.png\n",
    "            f\"{stem} x{scale}.png\",          # 带空格：0001 x4.png\n",
    "            f\"{stem.strip()}x{scale}.png\",   # 去除stem末尾空格\n",
    "        ]\n",
    "        \n",
    "        lr_path = None\n",
    "        for lr_name in lr_candidates:\n",
    "            candidate_path = os.path.join(lr_dir, lr_name)\n",
    "            if os.path.exists(candidate_path):\n",
    "                lr_path = candidate_path\n",
    "                break\n",
    "        \n",
    "        # 如果还没找到，尝试模糊匹配\n",
    "        if lr_path is None:\n",
    "            stem_clean = stem.strip()\n",
    "            for f in lr_files:\n",
    "                # 检查文件名是否包含stem和scale标记\n",
    "                f_stem = os.path.splitext(f)[0]\n",
    "                if f_stem.strip().replace(' ', '').startswith(stem_clean.replace(' ', '')) and f'x{scale}' in f:\n",
    "                    lr_path = os.path.join(lr_dir, f)\n",
    "                    break\n",
    "        \n",
    "        if lr_path and os.path.exists(lr_path):\n",
    "            paired.append((hr_path, lr_path))\n",
    "            # 达到最大数量时提前退出\n",
    "            if max_samples is not None and len(paired) >= max_samples:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"警告: 未找到配对LR: {hr_name} -> 尝试过: {lr_candidates[:2]}\")\n",
    "    \n",
    "    return paired\n",
    "\n",
    "def load_image_pair(hr_path, lr_path, hr_size=128, scale=4):\n",
    "    \"\"\"加载并预处理HR/LR图像对\"\"\"\n",
    "    lr_size = hr_size // scale\n",
    "    \n",
    "    # 读取图像\n",
    "    hr_img = Image.open(hr_path).convert('RGB')\n",
    "    lr_img = Image.open(lr_path).convert('RGB')\n",
    "    \n",
    "    # 获取原始尺寸\n",
    "    hr_w, hr_h = hr_img.size\n",
    "    lr_w, lr_h = lr_img.size\n",
    "    \n",
    "    # 确保HR尺寸足够\n",
    "    if hr_w < hr_size or hr_h < hr_size:\n",
    "        new_w = max(hr_w, hr_size)\n",
    "        new_h = max(hr_h, hr_size)\n",
    "        hr_img = hr_img.resize((new_w, new_h), Image.BICUBIC)\n",
    "        hr_w, hr_h = hr_img.size\n",
    "    \n",
    "    # 确保LR尺寸足够\n",
    "    if lr_w < lr_size or lr_h < lr_size:\n",
    "        new_w = max(lr_w, lr_size)\n",
    "        new_h = max(lr_h, lr_size)\n",
    "        lr_img = lr_img.resize((new_w, new_h), Image.BICUBIC)\n",
    "        lr_w, lr_h = lr_img.size\n",
    "    \n",
    "    # 随机裁剪位置（基于HR坐标）\n",
    "    max_x = max(0, hr_w - hr_size)\n",
    "    max_y = max(0, hr_h - hr_size)\n",
    "    x = np.random.randint(0, max_x + 1) if max_x > 0 else 0\n",
    "    y = np.random.randint(0, max_y + 1) if max_y > 0 else 0\n",
    "    \n",
    "    # 裁剪HR\n",
    "    hr_crop = hr_img.crop((x, y, x + hr_size, y + hr_size))\n",
    "    \n",
    "    # 对应位置裁剪LR（按比例缩放坐标）\n",
    "    lx = min(x // scale, max(0, lr_w - lr_size))\n",
    "    ly = min(y // scale, max(0, lr_h - lr_size))\n",
    "    lr_crop = lr_img.crop((lx, ly, lx + lr_size, ly + lr_size))\n",
    "    \n",
    "    # 转为numpy数组并归一化到[-1, 1]\n",
    "    hr_np = np.array(hr_crop).astype(np.float32) / 127.5 - 1.0\n",
    "    lr_np = np.array(lr_crop).astype(np.float32) / 127.5 - 1.0\n",
    "    \n",
    "    # HWC -> CHW\n",
    "    hr_np = hr_np.transpose(2, 0, 1)\n",
    "    lr_np = lr_np.transpose(2, 0, 1)\n",
    "    \n",
    "    return hr_np, lr_np\n",
    "\n",
    "class PairedDataGenerator:\n",
    "    \"\"\"成对数据生成器\"\"\"\n",
    "    def __init__(self, hr_dir, lr_dir, hr_size=128, scale=4, is_train=True, max_samples=None):\n",
    "        self.pairs = get_paired_paths(hr_dir, lr_dir, scale, max_samples)\n",
    "        self.hr_size = hr_size\n",
    "        self.scale = scale\n",
    "        self.is_train = is_train\n",
    "        print(f\"✅ 加载 {len(self.pairs)} 对图像\" + (f\" (限制: {max_samples})\" if max_samples else \"\"))\n",
    "        if len(self.pairs) > 0:\n",
    "            print(f\"   示例配对: {os.path.basename(self.pairs[0][0])} <-> {os.path.basename(self.pairs[0][1])}\")\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        hr_path, lr_path = self.pairs[index]\n",
    "        hr_np, lr_np = load_image_pair(hr_path, lr_path, self.hr_size, self.scale)\n",
    "        return hr_np, lr_np\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "def create_sr_dataset(hr_dir, lr_dir, hr_size=128, scale=4, batch_size=4, is_train=True, max_samples=None):\n",
    "    \"\"\"创建超分辨率数据集\n",
    "    \n",
    "    Args:\n",
    "        hr_dir: HR图像目录\n",
    "        lr_dir: LR图像目录\n",
    "        hr_size: HR patch尺寸\n",
    "        scale: 放大倍数\n",
    "        batch_size: 批大小\n",
    "        is_train: 是否为训练集\n",
    "        max_samples: 最大加载数量，None表示加载全部\n",
    "    \n",
    "    注意: batch_size必须小于数据量，否则会因drop_remainder=True导致0个batch\n",
    "    \"\"\"\n",
    "    generator = PairedDataGenerator(hr_dir, lr_dir, hr_size, scale, is_train, max_samples)\n",
    "    \n",
    "    if len(generator) == 0:\n",
    "        print(f\"❌ 未找到配对数据！请检查目录: {hr_dir} 和 {lr_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # 检查batch_size是否合理\n",
    "    if batch_size > len(generator):\n",
    "        print(f\"⚠️ 警告: BATCH_SIZE({batch_size}) > 数据量({len(generator)})，自动调整为 {len(generator)}\")\n",
    "        batch_size = len(generator)\n",
    "    \n",
    "    dataset = ds.GeneratorDataset(\n",
    "        source=generator,\n",
    "        column_names=[\"hr\", \"lr\"],\n",
    "        shuffle=is_train,\n",
    "        num_parallel_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    # 数据增强（仅训练集）- 同步翻转HR和LR\n",
    "    if is_train:\n",
    "        def sync_flip(hr, lr):\n",
    "            if np.random.random() > 0.5:\n",
    "                hr = np.flip(hr, axis=2).copy()  # 水平翻转 (CHW格式，axis=2是W)\n",
    "                lr = np.flip(lr, axis=2).copy()\n",
    "            return hr, lr\n",
    "        \n",
    "        # 使用map操作应用同步翻转\n",
    "        # 注意：这里简化处理，实际翻转在load_image_pair中已完成\n",
    "    \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "# 创建数据集\n",
    "print(\"\\n=== 创建数据集 ===\")\n",
    "train_dataset = create_sr_dataset(\n",
    "    os.path.join(DATA_ROOT, 'train_HR'),\n",
    "    os.path.join(DATA_ROOT, 'train_LR'),\n",
    "    hr_size=HR_SIZE, scale=SCALE, batch_size=BATCH_SIZE, is_train=True,\n",
    "    max_samples=MAX_TRAIN_SAMPLES  # 训练集加载数量限制\n",
    ")\n",
    "\n",
    "val_dataset = create_sr_dataset(\n",
    "    os.path.join(DATA_ROOT, 'val_HR'),\n",
    "    os.path.join(DATA_ROOT, 'val_LR'),\n",
    "    hr_size=HR_SIZE, scale=SCALE, batch_size=1, is_train=False,\n",
    "    max_samples=MAX_VAL_SAMPLES  # 验证集加载数量限制\n",
    ")\n",
    "\n",
    "if train_dataset and val_dataset:\n",
    "    print(f\"\\n训练集批次数: {train_dataset.get_dataset_size()}\")\n",
    "    print(f\"验证集批次数: {val_dataset.get_dataset_size()}\")\n",
    "else:\n",
    "    print(\"\\n❌ 数据集创建失败，请检查数据目录\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化数据样本\n",
    "def denormalize(img):\n",
    "    \"\"\"反归一化: [-1,1] -> [0,255]\"\"\"\n",
    "    img = (img * 127.5 + 127.5).clip(0, 255).astype(np.uint8)\n",
    "    if img.shape[0] == 3:  # CHW -> HWC\n",
    "        img = img.transpose(1, 2, 0)\n",
    "    return img\n",
    "\n",
    "# 获取一个batch进行可视化\n",
    "try:\n",
    "    sample = next(train_dataset.create_dict_iterator())\n",
    "    hr_batch = sample['hr'].asnumpy()\n",
    "    lr_batch = sample['lr'].asnumpy()\n",
    "    \n",
    "    print(f\"HR shape: {hr_batch.shape}\")\n",
    "    print(f\"LR shape: {lr_batch.shape}\")\n",
    "    \n",
    "    # 可视化前2对\n",
    "    n_show = min(2, hr_batch.shape[0])\n",
    "    fig, axes = plt.subplots(n_show, 2, figsize=(10, 5*n_show))\n",
    "    if n_show == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(n_show):\n",
    "        hr_img = denormalize(hr_batch[i])\n",
    "        lr_img = denormalize(lr_batch[i])\n",
    "        \n",
    "        axes[i, 0].imshow(lr_img)\n",
    "        axes[i, 0].set_title(f'LR ({lr_img.shape[0]}x{lr_img.shape[1]})')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(hr_img)\n",
    "        axes[i, 1].set_title(f'HR ({hr_img.shape[0]}x{hr_img.shape[1]})')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.suptitle('Training Data Samples (LR / HR Pairs)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\n✅ 数据加载验证成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 数据可视化失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 模型架构\n",
    "\n",
    "### 3.1 SRResNet 基线生成器\n",
    "- 16个残差块\n",
    "- 亚像素卷积（PixelShuffle）上采样\n",
    "- 适合像素级损失训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRResNet 生成器\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "from mindspore.common.initializer import Normal, HeNormal\n",
    "\n",
    "class ResidualBlock(nn.Cell):\n",
    "    \"\"\"残差块：Conv-BN-PReLU-Conv-BN + Skip\"\"\"\n",
    "    def __init__(self, channels=64):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1, pad_mode='pad', \n",
    "                               has_bias=False, weight_init=HeNormal())\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1, pad_mode='pad',\n",
    "                               has_bias=False, weight_init=HeNormal())\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def construct(self, x):\n",
    "        residual = x\n",
    "        out = self.prelu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return out + residual\n",
    "\n",
    "class PixelShuffle(nn.Cell):\n",
    "    \"\"\"亚像素卷积上采样\"\"\"\n",
    "    def __init__(self, scale):\n",
    "        super(PixelShuffle, self).__init__()\n",
    "        self.scale = scale\n",
    "    \n",
    "    def construct(self, x):\n",
    "        # x: (N, C*r^2, H, W) -> (N, C, H*r, W*r)\n",
    "        n, c, h, w = x.shape\n",
    "        r = self.scale\n",
    "        out_c = c // (r * r)\n",
    "        # 重塑并转置\n",
    "        x = x.view(n, out_c, r, r, h, w)\n",
    "        x = x.transpose(0, 1, 4, 2, 5, 3)  # (N, C, H, r, W, r)\n",
    "        x = x.view(n, out_c, h * r, w * r)\n",
    "        return x\n",
    "\n",
    "class UpsampleBlock(nn.Cell):\n",
    "    \"\"\"上采样块：Conv + PixelShuffle + PReLU\"\"\"\n",
    "    def __init__(self, in_channels, scale=2):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * (scale ** 2), 3, \n",
    "                              padding=1, pad_mode='pad', has_bias=False, weight_init=HeNormal())\n",
    "        self.pixel_shuffle = PixelShuffle(scale)\n",
    "        self.prelu = nn.PReLU()\n",
    "    \n",
    "    def construct(self, x):\n",
    "        return self.prelu(self.pixel_shuffle(self.conv(x)))\n",
    "\n",
    "class SRResNet(nn.Cell):\n",
    "    \"\"\"SRResNet 超分辨率生成器\n",
    "    \n",
    "    Args:\n",
    "        scale: 放大倍数（2, 3, 4）\n",
    "        n_residual: 残差块数量\n",
    "        n_features: 特征通道数\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=4, n_residual=16, n_features=64):\n",
    "        super(SRResNet, self).__init__()\n",
    "        self.scale = scale\n",
    "        \n",
    "        # 输入卷积\n",
    "        self.conv_input = nn.Conv2d(3, n_features, 9, padding=4, pad_mode='pad',\n",
    "                                    has_bias=False, weight_init=HeNormal())\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "        # 残差块\n",
    "        self.residual_blocks = nn.SequentialCell(\n",
    "            [ResidualBlock(n_features) for _ in range(n_residual)]\n",
    "        )\n",
    "        \n",
    "        # 残差后卷积\n",
    "        self.conv_mid = nn.Conv2d(n_features, n_features, 3, padding=1, pad_mode='pad',\n",
    "                                  has_bias=False, weight_init=HeNormal())\n",
    "        self.bn_mid = nn.BatchNorm2d(n_features)\n",
    "        \n",
    "        # 上采样（×4 = 两次×2）\n",
    "        upsample_layers = []\n",
    "        if scale == 4:\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 2))\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 2))\n",
    "        elif scale == 2:\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 2))\n",
    "        elif scale == 3:\n",
    "            upsample_layers.append(UpsampleBlock(n_features, 3))\n",
    "        self.upsample = nn.SequentialCell(upsample_layers)\n",
    "        \n",
    "        # 输出卷积\n",
    "        self.conv_output = nn.Conv2d(n_features, 3, 9, padding=4, pad_mode='pad',\n",
    "                                     has_bias=False, weight_init=HeNormal())\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def construct(self, x):\n",
    "        # 输入处理\n",
    "        out = self.prelu(self.conv_input(x))\n",
    "        residual = out\n",
    "        \n",
    "        # 残差块\n",
    "        out = self.residual_blocks(out)\n",
    "        out = self.bn_mid(self.conv_mid(out))\n",
    "        out = out + residual\n",
    "        \n",
    "        # 上采样\n",
    "        out = self.upsample(out)\n",
    "        \n",
    "        # 输出\n",
    "        out = self.tanh(self.conv_output(out))\n",
    "        return out\n",
    "\n",
    "# 验证生成器\n",
    "print(\"=== SRResNet 模型验证 ===\")\n",
    "generator = SRResNet(scale=SCALE, n_residual=16, n_features=64)\n",
    "test_lr = Tensor(np.random.randn(1, 3, LR_SIZE, LR_SIZE).astype(np.float32))\n",
    "test_sr = generator(test_lr)\n",
    "print(f\"输入 LR: {test_lr.shape}\")\n",
    "print(f\"输出 SR: {test_sr.shape}\")\n",
    "print(f\"期望 HR: (1, 3, {HR_SIZE}, {HR_SIZE})\")\n",
    "assert test_sr.shape == (1, 3, HR_SIZE, HR_SIZE), \"输出尺寸不匹配！\"\n",
    "print(\"✅ SRResNet 构建成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ESRGAN 判别器（PatchGAN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESRGAN 判别器\n",
    "class Discriminator(nn.Cell):\n",
    "    \"\"\"VGG风格判别器\n",
    "    \n",
    "    输出多尺度特征，用于感知损失\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def conv_block(in_ch, out_ch, stride=1, bn=True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, \n",
    "                         pad_mode='pad', has_bias=not bn, weight_init=HeNormal())\n",
    "            ]\n",
    "            if bn:\n",
    "                layers.append(nn.BatchNorm2d(out_ch))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "            return nn.SequentialCell(layers)\n",
    "        \n",
    "        self.features = nn.SequentialCell([\n",
    "            # 无BN的第一层\n",
    "            conv_block(in_channels, ndf, stride=1, bn=False),\n",
    "            conv_block(ndf, ndf, stride=2, bn=True),\n",
    "            # 128 -> 64\n",
    "            conv_block(ndf, ndf*2, stride=1, bn=True),\n",
    "            conv_block(ndf*2, ndf*2, stride=2, bn=True),\n",
    "            # 64 -> 32\n",
    "            conv_block(ndf*2, ndf*4, stride=1, bn=True),\n",
    "            conv_block(ndf*4, ndf*4, stride=2, bn=True),\n",
    "            # 32 -> 16\n",
    "            conv_block(ndf*4, ndf*8, stride=1, bn=True),\n",
    "            conv_block(ndf*8, ndf*8, stride=2, bn=True),\n",
    "            # 16 -> 8\n",
    "        ])\n",
    "        \n",
    "        # 分类头\n",
    "        self.classifier = nn.SequentialCell([\n",
    "            nn.Flatten(),\n",
    "            nn.Dense(ndf*8 * 8 * 8, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dense(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "    \n",
    "    def construct(self, x):\n",
    "        features = self.features(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "# 验证判别器\n",
    "print(\"\\n=== Discriminator 模型验证 ===\")\n",
    "discriminator = Discriminator(in_channels=3, ndf=64)\n",
    "test_hr = Tensor(np.random.randn(1, 3, HR_SIZE, HR_SIZE).astype(np.float32))\n",
    "test_out = discriminator(test_hr)\n",
    "print(f\"输入 HR: {test_hr.shape}\")\n",
    "print(f\"输出: {test_out.shape}\")\n",
    "print(\"✅ Discriminator 构建成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 损失函数\n",
    "\n",
    "- **像素损失（L1）**：保证像素级准确性\n",
    "- **感知损失（VGG）**：保证感知质量（可选）\n",
    "- **对抗损失（GAN）**：生成更真实的细节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数定义\n",
    "class SRLoss(nn.Cell):\n",
    "    \"\"\"超分辨率综合损失\n",
    "    \n",
    "    L_total = λ_pixel * L_pixel + λ_adv * L_adv\n",
    "    \n",
    "    Args:\n",
    "        lambda_pixel: 像素损失权重\n",
    "        lambda_adv: 对抗损失权重\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda_pixel=1.0, lambda_adv=0.001, label_smoothing=0.1):\n",
    "        super(SRLoss, self).__init__()\n",
    "        self.lambda_pixel = lambda_pixel\n",
    "        self.lambda_adv = lambda_adv\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "        self.bce_loss = nn.BCELoss(reduction='mean')\n",
    "    \n",
    "    def pixel_loss(self, sr, hr):\n",
    "        \"\"\"像素级L1损失\"\"\"\n",
    "        return self.l1_loss(sr, hr)\n",
    "    \n",
    "    def generator_loss(self, d_fake, sr, hr):\n",
    "        \"\"\"生成器总损失\"\"\"\n",
    "        # 像素损失\n",
    "        pixel_loss = self.l1_loss(sr, hr) * self.lambda_pixel\n",
    "        \n",
    "        # 对抗损失（生成器希望判别器输出接近1）\n",
    "        real_label = Tensor(1.0 - self.label_smoothing, mindspore.float32)\n",
    "        adv_loss = self.bce_loss(d_fake, ops.ones_like(d_fake) * real_label) * self.lambda_adv\n",
    "        \n",
    "        return pixel_loss + adv_loss, pixel_loss, adv_loss\n",
    "    \n",
    "    def discriminator_loss(self, d_real, d_fake):\n",
    "        \"\"\"判别器损失\"\"\"\n",
    "        real_label = Tensor(1.0 - self.label_smoothing, mindspore.float32)\n",
    "        fake_label = Tensor(self.label_smoothing, mindspore.float32)\n",
    "        \n",
    "        real_loss = self.bce_loss(d_real, ops.ones_like(d_real) * real_label)\n",
    "        fake_loss = self.bce_loss(d_fake, ops.zeros_like(d_fake) + fake_label)\n",
    "        \n",
    "        return (real_loss + fake_loss) / 2\n",
    "\n",
    "print(\"✅ 损失函数定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练网络封装\n",
    "from mindspore import save_checkpoint, load_checkpoint, load_param_into_net\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 参数命名前缀（避免冲突）\n",
    "def rename_params(net, prefix):\n",
    "    for param in net.get_parameters():\n",
    "        param.name = f\"{prefix}_{param.name}\"\n",
    "\n",
    "class SRTrainer:\n",
    "    \"\"\"超分辨率训练器\"\"\"\n",
    "    def __init__(self, generator, discriminator, loss_fn, \n",
    "                 lr_g=1e-4, lr_d=1e-4, beta1=0.9):\n",
    "        self.G = generator\n",
    "        self.D = discriminator\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "        # 重命名参数\n",
    "        rename_params(self.G, \"G\")\n",
    "        rename_params(self.D, \"D\")\n",
    "        \n",
    "        # 优化器\n",
    "        self.opt_G = nn.Adam(self.G.trainable_params(), learning_rate=lr_g, beta1=beta1)\n",
    "        self.opt_D = nn.Adam(self.D.trainable_params(), learning_rate=lr_d, beta1=beta1)\n",
    "        \n",
    "        # 梯度函数\n",
    "        self.grad_G = ops.value_and_grad(self._g_loss, None, self.opt_G.parameters)\n",
    "        self.grad_D = ops.value_and_grad(self._d_loss, None, self.opt_D.parameters)\n",
    "    \n",
    "    def _g_loss(self, lr, hr):\n",
    "        \"\"\"生成器前向 + 损失\"\"\"\n",
    "        sr = self.G(lr)\n",
    "        d_fake = self.D(sr)\n",
    "        total_loss, pixel_loss, adv_loss = self.loss_fn.generator_loss(d_fake, sr, hr)\n",
    "        return total_loss\n",
    "    \n",
    "    def _d_loss(self, lr, hr):\n",
    "        \"\"\"判别器前向 + 损失\"\"\"\n",
    "        sr = self.G(lr)\n",
    "        sr = ops.stop_gradient(sr)  # 不计算生成器梯度\n",
    "        d_real = self.D(hr)\n",
    "        d_fake = self.D(sr)\n",
    "        return self.loss_fn.discriminator_loss(d_real, d_fake)\n",
    "    \n",
    "    def train_step(self, lr, hr):\n",
    "        \"\"\"单步训练\"\"\"\n",
    "        # 训练生成器\n",
    "        g_loss, g_grads = self.grad_G(lr, hr)\n",
    "        self.opt_G(g_grads)\n",
    "        \n",
    "        # 训练判别器\n",
    "        d_loss, d_grads = self.grad_D(lr, hr)\n",
    "        self.opt_D(d_grads)\n",
    "        \n",
    "        return g_loss, d_loss\n",
    "    \n",
    "    def generate(self, lr):\n",
    "        \"\"\"生成SR图像\"\"\"\n",
    "        self.G.set_train(False)\n",
    "        sr = self.G(lr)\n",
    "        self.G.set_train(True)\n",
    "        return sr\n",
    "\n",
    "print(\"✅ 训练器定义完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估指标\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def calculate_psnr(sr, hr):\n",
    "    \"\"\"计算PSNR\"\"\"\n",
    "    sr_np = denormalize(sr)\n",
    "    hr_np = denormalize(hr)\n",
    "    return psnr(hr_np, sr_np, data_range=255)\n",
    "\n",
    "def calculate_ssim(sr, hr):\n",
    "    \"\"\"计算SSIM\"\"\"\n",
    "    sr_np = denormalize(sr)\n",
    "    hr_np = denormalize(hr)\n",
    "    return ssim(hr_np, sr_np, data_range=255, channel_axis=2)\n",
    "\n",
    "def evaluate(trainer, dataset):\n",
    "    \"\"\"评估模型\"\"\"\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    \n",
    "    trainer.G.set_train(False)\n",
    "    for batch in dataset.create_dict_iterator():\n",
    "        hr = batch['hr'].asnumpy()\n",
    "        lr = batch['lr']\n",
    "        \n",
    "        sr = trainer.G(lr).asnumpy()\n",
    "        \n",
    "        for i in range(sr.shape[0]):\n",
    "            psnr_list.append(calculate_psnr(sr[i], hr[i]))\n",
    "            ssim_list.append(calculate_ssim(sr[i], hr[i]))\n",
    "    \n",
    "    trainer.G.set_train(True)\n",
    "    return np.mean(psnr_list), np.mean(ssim_list)\n",
    "\n",
    "print(\"✅ 评估函数定义完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主训练循环\n",
    "import os\n",
    "\n",
    "# ===================== 两阶段训练配置 =====================\n",
    "# 第一阶段：设置 LAMBDA_ADV=0.0, PRETRAINED_G=None\n",
    "# 第二阶段：设置 LAMBDA_ADV=0.001, PRETRAINED_G=\"./ckpt_sr/G_final.ckpt\"\n",
    "# =========================================================\n",
    "\n",
    "# ===================== 两阶段训练配置 =====================\n",
    "# 第一阶段：设置 LAMBDA_ADV=0.0, PRETRAINED_G=None\n",
    "# 第二阶段：设置 LAMBDA_ADV=0.001, PRETRAINED_G=\"./ckpt_sr/G_final.ckpt\"\n",
    "# =========================================================\n",
    "\n",
    "# 超参数配置\n",
    "EPOCHS = 100 #######(可调) 建议：第一阶段100轮，第二阶段100轮\n",
    "EPOCHS = 100 #######(可调) 建议：第一阶段100轮，第二阶段100轮\n",
    "LR_G = 1e-4\n",
    "LR_D = 1e-4\n",
    "LAMBDA_PIXEL = 1.0\n",
    "LAMBDA_ADV = 0.0  ####### 第一阶段设为0.0，第二阶段设为0.001\n",
    "LAMBDA_ADV = 0.0  ####### 第一阶段设为0.0，第二阶段设为0.001\n",
    "SAVE_DIR = \"./ckpt_sr\"\n",
    "EVAL_INTERVAL = 20  # 评估间隔（每N轮评估一次） #######（可调）\n",
    "\n",
    "# 预训练权重路径（第一阶段设为None，第二阶段填入第一阶段的权重路径）\n",
    "PRETRAINED_G = None  ####### 第二阶段设为 \"./ckpt_sr/G_final.ckpt\"\n",
    "PRETRAINED_D = None  ####### 第二阶段可选 \"./ckpt_sr/D_final.ckpt\"\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 初始化模型\n",
    "print(\"=\" * 60)\n",
    "print(\"初始化模型...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G = SRResNet(scale=SCALE, n_residual=16, n_features=64)\n",
    "D = Discriminator(in_channels=3, ndf=64)\n",
    "\n",
    "# 重命名参数（必须在加载权重之前）\n",
    "rename_params(G, \"G\")\n",
    "rename_params(D, \"D\")\n",
    "\n",
    "# 加载预训练权重（第二阶段使用）\n",
    "if PRETRAINED_G is not None and os.path.exists(PRETRAINED_G):\n",
    "    param_dict = load_checkpoint(PRETRAINED_G)\n",
    "    load_param_into_net(G, param_dict)\n",
    "    print(f\"✅ 已加载生成器预训练权重: {PRETRAINED_G}\")\n",
    "\n",
    "if PRETRAINED_D is not None and os.path.exists(PRETRAINED_D):\n",
    "    param_dict = load_checkpoint(PRETRAINED_D)\n",
    "    load_param_into_net(D, param_dict)\n",
    "    print(f\"✅ 已加载判别器预训练权重: {PRETRAINED_D}\")\n",
    "\n",
    "\n",
    "# 重命名参数（必须在加载权重之前）\n",
    "rename_params(G, \"G\")\n",
    "rename_params(D, \"D\")\n",
    "\n",
    "# 加载预训练权重（第二阶段使用）\n",
    "if PRETRAINED_G is not None and os.path.exists(PRETRAINED_G):\n",
    "    param_dict = load_checkpoint(PRETRAINED_G)\n",
    "    load_param_into_net(G, param_dict)\n",
    "    print(f\"✅ 已加载生成器预训练权重: {PRETRAINED_G}\")\n",
    "\n",
    "if PRETRAINED_D is not None and os.path.exists(PRETRAINED_D):\n",
    "    param_dict = load_checkpoint(PRETRAINED_D)\n",
    "    load_param_into_net(D, param_dict)\n",
    "    print(f\"✅ 已加载判别器预训练权重: {PRETRAINED_D}\")\n",
    "\n",
    "loss_fn = SRLoss(lambda_pixel=LAMBDA_PIXEL, lambda_adv=LAMBDA_ADV)\n",
    "\n",
    "# 创建优化器（注意：不再调用rename_params，因为已经调用过了）\n",
    "opt_G = nn.Adam(G.trainable_params(), learning_rate=LR_G, beta1=0.9)\n",
    "opt_D = nn.Adam(D.trainable_params(), learning_rate=LR_D, beta1=0.9)\n",
    "\n",
    "# 梯度函数\n",
    "def _g_loss(lr, hr):\n",
    "    sr = G(lr)\n",
    "    d_fake = D(sr)\n",
    "    total_loss, pixel_loss, adv_loss = loss_fn.generator_loss(d_fake, sr, hr)\n",
    "    return total_loss\n",
    "\n",
    "def _d_loss(lr, hr):\n",
    "    sr = G(lr)\n",
    "    sr = ops.stop_gradient(sr)\n",
    "    d_real = D(hr)\n",
    "    d_fake = D(sr)\n",
    "    return loss_fn.discriminator_loss(d_real, d_fake)\n",
    "\n",
    "grad_G = ops.value_and_grad(_g_loss, None, opt_G.parameters)\n",
    "grad_D = ops.value_and_grad(_d_loss, None, opt_D.parameters)\n",
    "\n",
    "def train_step(lr, hr):\n",
    "    g_loss, g_grads = grad_G(lr, hr)\n",
    "    opt_G(g_grads)\n",
    "    \n",
    "    # 只有开启对抗损失时才训练判别器\n",
    "    if LAMBDA_ADV > 0:\n",
    "        d_loss, d_grads = grad_D(lr, hr)\n",
    "        opt_D(d_grads)\n",
    "    else:\n",
    "        d_loss = ops.zeros(1)\n",
    "    \n",
    "    return g_loss, d_loss\n",
    "\n",
    "# 创建优化器（注意：不再调用rename_params，因为已经调用过了）\n",
    "opt_G = nn.Adam(G.trainable_params(), learning_rate=LR_G, beta1=0.9)\n",
    "opt_D = nn.Adam(D.trainable_params(), learning_rate=LR_D, beta1=0.9)\n",
    "\n",
    "# 梯度函数\n",
    "def _g_loss(lr, hr):\n",
    "    sr = G(lr)\n",
    "    d_fake = D(sr)\n",
    "    total_loss, pixel_loss, adv_loss = loss_fn.generator_loss(d_fake, sr, hr)\n",
    "    return total_loss\n",
    "\n",
    "def _d_loss(lr, hr):\n",
    "    sr = G(lr)\n",
    "    sr = ops.stop_gradient(sr)\n",
    "    d_real = D(hr)\n",
    "    d_fake = D(sr)\n",
    "    return loss_fn.discriminator_loss(d_real, d_fake)\n",
    "\n",
    "grad_G = ops.value_and_grad(_g_loss, None, opt_G.parameters)\n",
    "grad_D = ops.value_and_grad(_d_loss, None, opt_D.parameters)\n",
    "\n",
    "def train_step(lr, hr):\n",
    "    g_loss, g_grads = grad_G(lr, hr)\n",
    "    opt_G(g_grads)\n",
    "    \n",
    "    # 只有开启对抗损失时才训练判别器\n",
    "    if LAMBDA_ADV > 0:\n",
    "        d_loss, d_grads = grad_D(lr, hr)\n",
    "        opt_D(d_grads)\n",
    "    else:\n",
    "        d_loss = ops.zeros(1)\n",
    "    \n",
    "    return g_loss, d_loss\n",
    "\n",
    "print(f\"生成器参数量: {sum(p.size for p in G.get_parameters()) / 1e6:.2f}M\")\n",
    "print(f\"判别器参数量: {sum(p.size for p in D.get_parameters()) / 1e6:.2f}M\")\n",
    "print(f\"\\n训练模式: {'GAN (对抗训练)' if LAMBDA_ADV > 0 else 'SRResNet (纯L1损失)'}\")\n",
    "print(f\"\\n训练模式: {'GAN (对抗训练)' if LAMBDA_ADV > 0 else 'SRResNet (纯L1损失)'}\")\n",
    "\n",
    "# 获取固定测试图\n",
    "fixed_lr = None\n",
    "fixed_hr = None\n",
    "try:\n",
    "    val_iter = val_dataset.create_dict_iterator()\n",
    "    val_sample = next(val_iter)\n",
    "    fixed_lr = val_sample['lr']\n",
    "    fixed_hr = val_sample['hr'].asnumpy()[0]\n",
    "    print(f\"固定测试图 LR shape: {fixed_lr.shape}\")\n",
    "    print(f\"固定测试图 LR shape: {fixed_lr.shape}\")\n",
    "except:\n",
    "    print(\"警告: 无法加载验证数据\")\n",
    "\n",
    "# 记录训练历史\n",
    "history = {\n",
    "    'g_loss': [],\n",
    "    'd_loss': [],\n",
    "    'psnr': [],\n",
    "    'ssim': []\n",
    "}\n",
    "\n",
    "print(f\"\\n=== 开始训练 (共 {EPOCHS} 轮) ===\")\n",
    "print(f\"配置: LR_G={LR_G}, LR_D={LR_D}, λ_pixel={LAMBDA_PIXEL}, λ_adv={LAMBDA_ADV}\")\n",
    "\n",
    "best_psnr = 0\n",
    "n_batches = train_dataset.get_dataset_size()\n",
    "\n",
    "# 使用tqdm创建epoch进度条\n",
    "epoch_pbar = tqdm(range(1, EPOCHS + 1), desc=\"训练进度\", unit=\"epoch\")\n",
    "\n",
    "for epoch in epoch_pbar:\n",
    "    G.set_train(True)\n",
    "    D.set_train(True)\n",
    "    \n",
    "    epoch_g_loss = 0\n",
    "    epoch_d_loss = 0\n",
    "    n_steps = 0\n",
    "    \n",
    "    # 训练一个epoch\n",
    "    for batch in train_dataset.create_dict_iterator():\n",
    "        lr = batch['lr']\n",
    "        hr = batch['hr']\n",
    "        \n",
    "        g_loss, d_loss = train_step(lr, hr)\n",
    "        g_loss, d_loss = train_step(lr, hr)\n",
    "        \n",
    "        epoch_g_loss += float(g_loss.asnumpy())\n",
    "        epoch_d_loss += float(d_loss.asnumpy()) if LAMBDA_ADV > 0 else 0\n",
    "        epoch_d_loss += float(d_loss.asnumpy()) if LAMBDA_ADV > 0 else 0\n",
    "        n_steps += 1\n",
    "    \n",
    "    # 计算平均损失\n",
    "    avg_g_loss = epoch_g_loss / max(n_steps, 1)\n",
    "    avg_d_loss = epoch_d_loss / max(n_steps, 1)\n",
    "    history['g_loss'].append(avg_g_loss)\n",
    "    history['d_loss'].append(avg_d_loss)\n",
    "    \n",
    "    # 更新进度条显示信息\n",
    "    if LAMBDA_ADV > 0:\n",
    "        epoch_pbar.set_postfix({'G_loss': f'{avg_g_loss:.4f}', 'D_loss': f'{avg_d_loss:.4f}'})\n",
    "    else:\n",
    "        epoch_pbar.set_postfix({'L1_loss': f'{avg_g_loss:.4f}'})\n",
    "    if LAMBDA_ADV > 0:\n",
    "        epoch_pbar.set_postfix({'G_loss': f'{avg_g_loss:.4f}', 'D_loss': f'{avg_d_loss:.4f}'})\n",
    "    else:\n",
    "        epoch_pbar.set_postfix({'L1_loss': f'{avg_g_loss:.4f}'})\n",
    "    \n",
    "    # 每EVAL_INTERVAL轮评估和可视化\n",
    "    if epoch % EVAL_INTERVAL == 0:\n",
    "        # 评估\n",
    "        G.set_train(False)\n",
    "        psnr_list, ssim_list = [], []\n",
    "        for val_batch in val_dataset.create_dict_iterator():\n",
    "            val_hr = val_batch['hr'].asnumpy()\n",
    "            val_sr = G(val_batch['lr']).asnumpy()\n",
    "            for i in range(val_sr.shape[0]):\n",
    "                psnr_list.append(calculate_psnr(val_sr[i], val_hr[i]))\n",
    "                ssim_list.append(calculate_ssim(val_sr[i], val_hr[i]))\n",
    "        G.set_train(True)\n",
    "        \n",
    "        avg_psnr, avg_ssim = np.mean(psnr_list), np.mean(ssim_list)\n",
    "        G.set_train(False)\n",
    "        psnr_list, ssim_list = [], []\n",
    "        for val_batch in val_dataset.create_dict_iterator():\n",
    "            val_hr = val_batch['hr'].asnumpy()\n",
    "            val_sr = G(val_batch['lr']).asnumpy()\n",
    "            for i in range(val_sr.shape[0]):\n",
    "                psnr_list.append(calculate_psnr(val_sr[i], val_hr[i]))\n",
    "                ssim_list.append(calculate_ssim(val_sr[i], val_hr[i]))\n",
    "        G.set_train(True)\n",
    "        \n",
    "        avg_psnr, avg_ssim = np.mean(psnr_list), np.mean(ssim_list)\n",
    "        history['psnr'].append(avg_psnr)\n",
    "        history['ssim'].append(avg_ssim)\n",
    "        \n",
    "        # 更新进度条\n",
    "        # 更新进度条\n",
    "        epoch_pbar.set_postfix({\n",
    "            'loss': f'{avg_g_loss:.4f}',\n",
    "            'loss': f'{avg_g_loss:.4f}',\n",
    "            'PSNR': f'{avg_psnr:.2f}dB',\n",
    "            'SSIM': f'{avg_ssim:.4f}'\n",
    "        })\n",
    "        \n",
    "        tqdm.write(f\"\\nEpoch {epoch:3d}/{EPOCHS} | Loss: {avg_g_loss:.4f} | \"\n",
    "        tqdm.write(f\"\\nEpoch {epoch:3d}/{EPOCHS} | Loss: {avg_g_loss:.4f} | \"\n",
    "              f\"PSNR: {avg_psnr:.2f}dB | SSIM: {avg_ssim:.4f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if avg_psnr > best_psnr:\n",
    "            best_psnr = avg_psnr\n",
    "            save_checkpoint(G, os.path.join(SAVE_DIR, \"G_best.ckpt\"))\n",
    "            tqdm.write(f\"   ✅ 保存最佳模型 (PSNR: {best_psnr:.2f}dB)\")\n",
    "        \n",
    "        # 可视化\n",
    "        if fixed_lr is not None:\n",
    "            G.set_train(False)\n",
    "            sr = G(fixed_lr).asnumpy()[0]\n",
    "            G.set_train(True)\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            lr_img = denormalize(fixed_lr.asnumpy()[0])\n",
    "            axes[0].imshow(lr_img)\n",
    "            axes[0].set_title(f'LR Input ({lr_img.shape[0]}x{lr_img.shape[1]})')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            sr_img = denormalize(sr)\n",
    "            axes[1].imshow(sr_img)\n",
    "            axes[1].set_title(f'SR Output ({sr_img.shape[0]}x{sr_img.shape[1]})')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            hr_img = denormalize(fixed_hr)\n",
    "            axes[2].imshow(hr_img)\n",
    "            axes[2].set_title(f'HR Ground Truth ({hr_img.shape[0]}x{hr_img.shape[1]})')\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            plt.suptitle(f'Epoch {epoch} - PSNR: {avg_psnr:.2f}dB, SSIM: {avg_ssim:.4f}', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(SAVE_DIR, f'result_epoch_{epoch}.png'), dpi=150)\n",
    "            plt.show()\n",
    "    \n",
    "    # 定期保存检查点\n",
    "    if epoch % EVAL_INTERVAL == 0:\n",
    "        save_checkpoint(G, os.path.join(SAVE_DIR, f\"G_epoch_{epoch}.ckpt\"))\n",
    "        if LAMBDA_ADV > 0:\n",
    "            save_checkpoint(D, os.path.join(SAVE_DIR, f\"D_epoch_{epoch}.ckpt\"))\n",
    "        if LAMBDA_ADV > 0:\n",
    "            save_checkpoint(D, os.path.join(SAVE_DIR, f\"D_epoch_{epoch}.ckpt\"))\n",
    "\n",
    "# 保存最终模型\n",
    "save_checkpoint(G, os.path.join(SAVE_DIR, \"G_final.ckpt\"))\n",
    "save_checkpoint(D, os.path.join(SAVE_DIR, \"D_final.ckpt\"))\n",
    "print(f\"\\n🎉 训练完成！最佳PSNR: {best_psnr:.2f}dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练曲线\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 损失曲线\n",
    "axes[0].plot(history['g_loss'], label='Generator Loss', color='blue')\n",
    "axes[0].plot(history['d_loss'], label='Discriminator Loss', color='red')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PSNR曲线\n",
    "eval_epochs = list(range(1, len(history['psnr'])*10+1, 10))\n",
    "if len(eval_epochs) > len(history['psnr']):\n",
    "    eval_epochs = eval_epochs[:len(history['psnr'])]\n",
    "axes[1].plot(eval_epochs, history['psnr'], marker='o', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('PSNR (dB)')\n",
    "axes[1].set_title('PSNR on Validation Set')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM曲线\n",
    "axes[2].plot(eval_epochs, history['ssim'], marker='s', color='orange')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('SSIM')\n",
    "axes[2].set_title('SSIM on Validation Set')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'training_curves.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型进行评估\n",
    "print(\"=== 加载最佳模型进行评估 ===\")\n",
    "\n",
    "G_eval = SRResNet(scale=SCALE, n_residual=16, n_features=64)\n",
    "rename_params(G_eval, \"G\")\n",
    "\n",
    "ckpt_path = os.path.join(SAVE_DIR, \"G_best.ckpt\")\n",
    "if os.path.exists(ckpt_path):\n",
    "    param_dict = load_checkpoint(ckpt_path)\n",
    "    load_param_into_net(G_eval, param_dict)\n",
    "    print(f\"✅ 已加载模型: {ckpt_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ 未找到最佳模型，使用当前模型\")\n",
    "    G_eval = G\n",
    "\n",
    "G_eval.set_train(False)\n",
    "\n",
    "# 在验证集上评估\n",
    "print(\"\\n[验证集评估]\")\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "\n",
    "for batch in val_dataset.create_dict_iterator():\n",
    "    hr = batch['hr'].asnumpy()\n",
    "    lr = batch['lr']\n",
    "    sr = G_eval(lr).asnumpy()\n",
    "    \n",
    "    for i in range(sr.shape[0]):\n",
    "        p = calculate_psnr(sr[i], hr[i])\n",
    "        s = calculate_ssim(sr[i], hr[i])\n",
    "        psnr_list.append(p)\n",
    "        ssim_list.append(s)\n",
    "        print(f\"  样本 {len(psnr_list)}: PSNR={p:.2f}dB, SSIM={s:.4f}\")\n",
    "\n",
    "print(f\"\\n平均 PSNR: {np.mean(psnr_list):.2f}dB\")\n",
    "print(f\"平均 SSIM: {np.mean(ssim_list):.4f}\")\n",
    "\n",
    "# 验收标准判断\n",
    "print(\"\\n[验收标准检查]\")\n",
    "if np.mean(psnr_list) >= 28:\n",
    "    print(f\"✅ PSNR ≥ 28dB (实际: {np.mean(psnr_list):.2f}dB)\")\n",
    "else:\n",
    "    print(f\"❌ PSNR < 28dB (实际: {np.mean(psnr_list):.2f}dB)，建议增加训练轮数\")\n",
    "\n",
    "if np.mean(ssim_list) >= 0.80:\n",
    "    print(f\"✅ SSIM ≥ 0.80 (实际: {np.mean(ssim_list):.4f})\")\n",
    "else:\n",
    "    print(f\"❌ SSIM < 0.80 (实际: {np.mean(ssim_list):.4f})，建议调整损失权重\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 推理与可视化\n",
    "\n",
    "对真实旧照片进行修复增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旧照片推理（优化版：显存释放 + 大图分块处理）\n",
    "from PIL import Image\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# ====== 关键：释放训练占用的显存 ======\n",
    "print(\"=== 释放训练占用的显存 ===\")\n",
    "\n",
    "# 删除训练时的大对象\n",
    "vars_to_delete = ['G', 'D', 'trainer', 'train_dataset', 'val_dataset', \n",
    "                  'fixed_lr', 'fixed_hr', 'history']\n",
    "for var_name in vars_to_delete:\n",
    "    if var_name in dir():\n",
    "        try:\n",
    "            exec(f\"del {var_name}\")\n",
    "            print(f\"  已删除: {var_name}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# 强制Python垃圾回收\n",
    "gc.collect()\n",
    "\n",
    "# MindSpore 显存清理\n",
    "try:\n",
    "    from mindspore import context\n",
    "    # 重置计算图缓存\n",
    "    context.set_context(reserve_class_name_in_scope=False)\n",
    "    print(\"✅ 显存清理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 显存清理警告: {e}\")\n",
    "\n",
    "# ====== 配置 ======\n",
    "OLD_PHOTOS_DIR = os.path.join(DATA_ROOT, 'old_photos')\n",
    "OUTPUT_DIR = \"./output_sr\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 大图处理参数\n",
    "MAX_INPUT_SIZE = 256  # 最大输入尺寸（超过则缩放）\n",
    "TILE_SIZE = 128       # 分块大小（显存不足时使用）\n",
    "TILE_OVERLAP = 16     # 分块重叠（避免接缝）\n",
    "\n",
    "def inference_single_safe(model, image_path, scale=4, max_size=256):\n",
    "    \"\"\"安全的单张图像推理（支持大图缩放）\n",
    "    \n",
    "    Args:\n",
    "        model: 生成器模型\n",
    "        image_path: 图像路径\n",
    "        scale: 放大倍数\n",
    "        max_size: 最大输入尺寸，超过则先缩放\n",
    "    \"\"\"\n",
    "    # 读取图像\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    original_size = img.size  # (W, H)\n",
    "    print(f\"   原始尺寸: {original_size[0]}x{original_size[1]}\")\n",
    "    \n",
    "    # 如果图像太大，先缩放到max_size\n",
    "    w, h = original_size\n",
    "    if max(w, h) > max_size:\n",
    "        ratio = max_size / max(w, h)\n",
    "        new_w = int(w * ratio)\n",
    "        new_h = int(h * ratio)\n",
    "        img_input = img.resize((new_w, new_h), Image.BICUBIC)\n",
    "        print(f\"   缩放至: {new_w}x{new_h} (显存优化)\")\n",
    "    else:\n",
    "        img_input = img\n",
    "    \n",
    "    # 预处理\n",
    "    img_np = np.array(img_input).astype(np.float32) / 127.5 - 1.0\n",
    "    img_np = img_np.transpose(2, 0, 1)  # HWC -> CHW\n",
    "    img_tensor = Tensor(img_np[np.newaxis, ...], mindspore.float32)\n",
    "    \n",
    "    # 推理\n",
    "    model.set_train(False)\n",
    "    sr_tensor = model(img_tensor)\n",
    "    \n",
    "    # 后处理\n",
    "    sr_np = sr_tensor.asnumpy()[0]\n",
    "    sr_np = (sr_np * 127.5 + 127.5).clip(0, 255).astype(np.uint8)\n",
    "    sr_np = sr_np.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    sr_img = Image.fromarray(sr_np)\n",
    "    \n",
    "    return img, sr_img\n",
    "\n",
    "def inference_tiled(model, image_path, scale=4, tile_size=128, overlap=16):\n",
    "    \"\"\"分块推理（适用于超大图像）\n",
    "    \n",
    "    将大图切分成小块分别处理，最后拼接\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    original_size = img.size\n",
    "    w, h = original_size\n",
    "    print(f\"   原始尺寸: {w}x{h}\")\n",
    "    print(f\"   使用分块处理: tile={tile_size}, overlap={overlap}\")\n",
    "    \n",
    "    # 输出图像尺寸\n",
    "    out_w, out_h = w * scale, h * scale\n",
    "    sr_result = np.zeros((out_h, out_w, 3), dtype=np.float32)\n",
    "    sr_count = np.zeros((out_h, out_w, 1), dtype=np.float32)\n",
    "    \n",
    "    # 分块处理\n",
    "    stride = tile_size - overlap\n",
    "    tiles_x = (w + stride - 1) // stride\n",
    "    tiles_y = (h + stride - 1) // stride\n",
    "    total_tiles = tiles_x * tiles_y\n",
    "    \n",
    "    tile_idx = 0\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            tile_idx += 1\n",
    "            # 计算实际tile区域\n",
    "            x1, y1 = x, y\n",
    "            x2 = min(x + tile_size, w)\n",
    "            y2 = min(y + tile_size, h)\n",
    "            \n",
    "            # 裁剪tile\n",
    "            tile = img.crop((x1, y1, x2, y2))\n",
    "            tile_w, tile_h = tile.size\n",
    "            \n",
    "            # 预处理\n",
    "            tile_np = np.array(tile).astype(np.float32) / 127.5 - 1.0\n",
    "            tile_np = tile_np.transpose(2, 0, 1)\n",
    "            tile_tensor = Tensor(tile_np[np.newaxis, ...], mindspore.float32)\n",
    "            \n",
    "            # 推理\n",
    "            model.set_train(False)\n",
    "            sr_tile = model(tile_tensor).asnumpy()[0]\n",
    "            sr_tile = sr_tile.transpose(1, 2, 0)  # CHW -> HWC\n",
    "            \n",
    "            # 放置到输出位置\n",
    "            ox1, oy1 = x1 * scale, y1 * scale\n",
    "            ox2, oy2 = ox1 + tile_w * scale, oy1 + tile_h * scale\n",
    "            \n",
    "            sr_result[oy1:oy2, ox1:ox2] += sr_tile\n",
    "            sr_count[oy1:oy2, ox1:ox2] += 1\n",
    "            \n",
    "            if tile_idx % 10 == 0:\n",
    "                print(f\"   进度: {tile_idx}/{total_tiles}\")\n",
    "    \n",
    "    # 平均重叠区域\n",
    "    sr_result = sr_result / np.maximum(sr_count, 1)\n",
    "    sr_result = (sr_result * 127.5 + 127.5).clip(0, 255).astype(np.uint8)\n",
    "    sr_img = Image.fromarray(sr_result)\n",
    "    \n",
    "    return img, sr_img\n",
    "\n",
    "# ====== 重新加载推理模型（轻量级） ======\n",
    "print(\"\\n=== 重新加载推理模型 ===\")\n",
    "G_eval = SRResNet(scale=SCALE, n_residual=16, n_features=64)\n",
    "rename_params(G_eval, \"G\")\n",
    "\n",
    "ckpt_path = os.path.join(SAVE_DIR, \"G_best.ckpt\")\n",
    "if os.path.exists(ckpt_path):\n",
    "    param_dict = load_checkpoint(ckpt_path)\n",
    "    load_param_into_net(G_eval, param_dict)\n",
    "    print(f\"✅ 已加载模型: {ckpt_path}\")\n",
    "else:\n",
    "    print(f\"❌ 未找到模型: {ckpt_path}\")\n",
    "    raise FileNotFoundError(f\"请确保模型文件存在: {ckpt_path}\")\n",
    "\n",
    "G_eval.set_train(False)\n",
    "\n",
    "# ====== 处理所有旧照片 ======\n",
    "print(\"\\n=== 旧照片修复推理 ===\")\n",
    "old_photos = [f for f in os.listdir(OLD_PHOTOS_DIR) if f.lower().endswith(IMAGE_EXTENSIONS)]\n",
    "print(f\"找到 {len(old_photos)} 张旧照片\")\n",
    "\n",
    "for photo_name in old_photos:\n",
    "    photo_path = os.path.join(OLD_PHOTOS_DIR, photo_name)\n",
    "    print(f\"\\n处理: {photo_name}\")\n",
    "    \n",
    "    try:\n",
    "        # 检查图像尺寸决定处理方式\n",
    "        with Image.open(photo_path) as tmp_img:\n",
    "            w, h = tmp_img.size\n",
    "        \n",
    "        if max(w, h) > 512:\n",
    "            # 超大图：使用分块处理\n",
    "            print(f\"   [分块模式] 图像较大 ({w}x{h})\")\n",
    "            original, restored = inference_tiled(G_eval, photo_path, SCALE, \n",
    "                                                  tile_size=TILE_SIZE, overlap=TILE_OVERLAP)\n",
    "        elif max(w, h) > MAX_INPUT_SIZE:\n",
    "            # 大图：缩放后处理\n",
    "            print(f\"   [缩放模式] 图像中等 ({w}x{h})\")\n",
    "            original, restored = inference_single_safe(G_eval, photo_path, SCALE, MAX_INPUT_SIZE)\n",
    "        else:\n",
    "            # 小图：直接处理\n",
    "            print(f\"   [直接模式] 图像较小 ({w}x{h})\")\n",
    "            original, restored = inference_single_safe(G_eval, photo_path, SCALE, max_size=w)\n",
    "        \n",
    "        # 保存结果\n",
    "        stem = os.path.splitext(photo_name)[0]\n",
    "        restored.save(os.path.join(OUTPUT_DIR, f\"{stem}_restored.png\"))\n",
    "        \n",
    "        # 可视化对比\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "        \n",
    "        axes[0].imshow(original)\n",
    "        axes[0].set_title(f'Original ({original.size[0]}x{original.size[1]})', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(restored)\n",
    "        axes[1].set_title(f'Restored ({restored.size[0]}x{restored.size[1]})', fontsize=12)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Old Photo Restoration: {photo_name}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, f\"{stem}_comparison.png\"), dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"   ✅ 保存到: {OUTPUT_DIR}/{stem}_restored.png\")\n",
    "        \n",
    "        # 每张图后清理一次\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 处理失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n🎉 推理完成！结果保存在: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 项目总结\n",
    "\n",
    "### 完成内容\n",
    "1. ✅ 环境搭建与验证（MindSpore 2.2.14）\n",
    "2. ✅ 数据集加载（LR/HR配对，支持随机裁剪和增强）\n",
    "3. ✅ SRResNet基线生成器（16残差块 + PixelShuffle上采样）\n",
    "4. ✅ ESRGAN判别器（VGG风格）\n",
    "5. ✅ 损失函数（像素L1 + 对抗损失）\n",
    "6. ✅ 训练循环（支持PSNR/SSIM评估）\n",
    "7. ✅ 模型保存与加载\n",
    "8. ✅ 旧照片推理与可视化\n",
    "\n",
    "### 评估指标\n",
    "- PSNR: 越高越好（目标 ≥28dB）\n",
    "- SSIM: 越高越好（目标 ≥0.80）\n",
    "\n",
    "### 优化建议\n",
    "1. 增加训练数据量（推荐 ≥800对）\n",
    "2. 添加感知损失（VGG特征）\n",
    "3. 使用RRDB替代ResBlock（ESRGAN）\n",
    "4. 数据增强：旋转、缩放、颜色抖动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"高分辨率图像修复与增强项目 - 完成\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n模型保存路径: {SAVE_DIR}\")\n",
    "print(f\"推理结果路径: {OUTPUT_DIR}\")\n",
    "print(\"\\n项目文件:\")\n",
    "print(\"  - G_best.ckpt: 最佳生成器权重\")\n",
    "print(\"  - G_final.ckpt: 最终生成器权重\")\n",
    "print(\"  - training_curves.png: 训练曲线\")\n",
    "print(\"  - result_epoch_*.png: 各轮结果\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
