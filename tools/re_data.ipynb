{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534bffce",
   "metadata": {},
   "source": [
    "# Êï∞ÊçÆÈõÜÂáÜÂ§á\n",
    "## HR‚ÜíLR ÂêàÊàêÈÄÄÂåñÊµÅÊ∞¥Á∫ø\n",
    "ÔºàÈ´òÊñØ/ËøêÂä®Ê®°Á≥ä ‚Üí ‰∏ãÈááÊ†∑ √ó2/√ó3/√ó4 ‚Üí Âô™Â£∞/JPEG ‚Üí ÂèØÈÄâÂàíÁóïÂè†Âä†Ôºâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b04724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== DIV2K Êï∞ÊçÆÈõÜ‰∏ãËΩΩÔºàLinux ‰∫ëÊúçÂä°Âô®‰ΩøÁî®Ôºâ ==============\n",
    "# Âú® Linux ÊúçÂä°Âô®‰∏äËøêË°åÊ≠§ÂçïÂÖÉÊ†º‰∏ãËΩΩ DIV2K HR Êï∞ÊçÆÈõÜ\n",
    "# ‰∏ãËΩΩÂÆåÊàêÂêé‰ºöËá™Âä®Ëß£ÂéãÂπ∂Êï¥ÁêÜÁõÆÂΩïÁªìÊûÑ\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# ÈÖçÁΩÆË∑ØÂæÑÔºàÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπÔºâ\n",
    "DATA_ROOT = Path(\"../data\")  # Áõ∏ÂØπ‰∫é notebook ÁöÑÊï∞ÊçÆÁõÆÂΩï\n",
    "\n",
    "# ÂàõÂª∫ÁõÆÂΩï\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(DATA_ROOT)\n",
    "\n",
    "# DIV2K ‰∏ãËΩΩÈìæÊé•\n",
    "URLS = {\n",
    "    \"train_HR\": \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\",\n",
    "    \"valid_HR\": \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\",\n",
    "}\n",
    "\n",
    "def download_and_extract(name, url):\n",
    "    zip_file = f\"DIV2K_{name}.zip\"\n",
    "    extract_dir = f\"DIV2K_{name}\"\n",
    "    target_dir = \"train_HR\" if \"train\" in name else \"val_HR\"\n",
    "    \n",
    "    # Ê£ÄÊü•ÊòØÂê¶Â∑≤Â≠òÂú®\n",
    "    if Path(target_dir).exists() and len(list(Path(target_dir).glob(\"*.png\"))) > 50:\n",
    "        print(f\"[SKIP] {target_dir} already exists with images\")\n",
    "        return\n",
    "    \n",
    "    # ‰∏ãËΩΩ\n",
    "    if not Path(zip_file).exists():\n",
    "        print(f\"[DL] Downloading {name}...\")\n",
    "        # ‰ΩøÁî® wgetÔºàLinux Â∏∏Áî®ÔºâÊàñ curl\n",
    "        result = subprocess.run(\n",
    "            [\"wget\", \"-c\", \"-O\", zip_file, url],\n",
    "            capture_output=False\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            # Â∞ùËØï curl\n",
    "            subprocess.run([\"curl\", \"-L\", \"-C\", \"-\", \"-o\", zip_file, url])\n",
    "    else:\n",
    "        print(f\"[OK] {zip_file} already downloaded\")\n",
    "    \n",
    "    # Ëß£Âéã\n",
    "    if not Path(extract_dir).exists():\n",
    "        print(f\"[ZIP] Extracting {zip_file}...\")\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zf:\n",
    "            zf.extractall(\".\")\n",
    "    \n",
    "    # ÈáçÂëΩÂêçÂà∞ÁõÆÊ†áÁõÆÂΩï\n",
    "    if Path(extract_dir).exists() and not Path(target_dir).exists():\n",
    "        Path(extract_dir).rename(target_dir)\n",
    "        print(f\"[OK] Moved to {target_dir}\")\n",
    "    \n",
    "    print(f\"[DONE] {target_dir}: {len(list(Path(target_dir).glob('*.png')))} images\")\n",
    "\n",
    "# ÊâßË°å‰∏ãËΩΩ\n",
    "for name, url in URLS.items():\n",
    "    download_and_extract(name, url)\n",
    "\n",
    "# ÂõûÂà∞ÂéüÁõÆÂΩï\n",
    "os.chdir(\"..\")\n",
    "print(\"\\n[COMPLETE] Dataset ready. Run next cells to generate LR images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fc0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËØªÂèñ data ‰∏≠ HR Âπ∂ÂÅöÂø´ÈÄüÊ£ÄÊü•ÔºàÂú®ÈÖçÁΩÆÂçïÂÖÉÂâçÊâßË°åÔºâ\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Ëá™Âä®Ê£ÄÊµãË∑ØÂæÑÔºàÂÖºÂÆπ Windows Âíå LinuxÔºâ\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "if (NOTEBOOK_DIR / \"data\").exists():\n",
    "    ROOT = NOTEBOOK_DIR / \"data\"\n",
    "elif (NOTEBOOK_DIR.parent / \"data\").exists():\n",
    "    ROOT = NOTEBOOK_DIR.parent / \"data\"\n",
    "else:\n",
    "    # ÊâãÂä®ÊåáÂÆöÔºàÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπÔºâ\n",
    "    ROOT = Path(\"../data\")\n",
    "\n",
    "ROOT = str(ROOT.resolve())\n",
    "EXTS = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "\n",
    "print(f\"Data root: {ROOT}\")\n",
    "\n",
    "for sp in ['train', 'val']:\n",
    "    hr_dir = os.path.join(ROOT, f'{sp}_HR')\n",
    "    exists = os.path.isdir(hr_dir)\n",
    "    files = [f for f in os.listdir(hr_dir) if f.lower().endswith(EXTS)] if exists else []\n",
    "    print(f'{sp} HR: {hr_dir} | exists: {exists} | count: {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc25075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, math, random, hashlib\n",
    "from typing import Tuple, List, Optional\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from pathlib import Path\n",
    "\n",
    "# ============== ÈÖçÁΩÆÔºàËá™Âä®Ê£ÄÊµãË∑ØÂæÑÔºåÂÖºÂÆπ Windows/LinuxÔºâ ==============\n",
    "# ‰ºòÂÖà‰ΩøÁî®‰∏ä‰∏Ä‰∏™ÂçïÂÖÉÊ†ºÊ£ÄÊµãÂà∞ÁöÑ ROOTÔºåÂê¶ÂàôËá™Âä®Ê£ÄÊµã\n",
    "if 'ROOT' in dir():\n",
    "    DATA_ROOT = ROOT\n",
    "else:\n",
    "    NOTEBOOK_DIR = Path(os.getcwd())\n",
    "    if (NOTEBOOK_DIR / \"data\").exists():\n",
    "        DATA_ROOT = str((NOTEBOOK_DIR / \"data\").resolve())\n",
    "    elif (NOTEBOOK_DIR.parent / \"data\").exists():\n",
    "        DATA_ROOT = str((NOTEBOOK_DIR.parent / \"data\").resolve())\n",
    "    else:\n",
    "        DATA_ROOT = \"../data\"\n",
    "\n",
    "SPLITS    = ['train', 'val']\n",
    "SCALES    = [4]             # ÂèØËÆæ‰∏∫ [2,3,4]ÔºõÂΩìÂâçÈªòËÆ§Âè™ÂÅö x4\n",
    "SEED      = 42\n",
    "OVERLAY_DIR = os.path.join(DATA_ROOT, 'overlays')\n",
    "\n",
    "# ÂèÇÊï∞Âå∫Èó¥ÔºàÂèØË∞ÉÔºâ\n",
    "BLUR_GAUSS_SIGMA = (0.0, 1.6)\n",
    "MOTION_KSIZE     = (3, 11)\n",
    "MOTION_ANGLE     = (0, 180)\n",
    "GAUSS_NOISE_STD  = (0.0, 6.0)\n",
    "SP_NOISE_PROB    = (0.0, 0.01)\n",
    "JPEG_QUALITY     = (60, 95)\n",
    "OVERLAY_PROB     = 0.25\n",
    "OVERLAY_ALPHA    = (0.1, 0.5)\n",
    "OVERLAY_SCALE    = (0.5, 1.5)\n",
    "\n",
    "print('DATA_ROOT =', DATA_ROOT)\n",
    "\n",
    "def list_images(folder, exts=('.png','.jpg','.jpeg','.bmp')):\n",
    "    if not os.path.isdir(folder):\n",
    "        return []\n",
    "    names = [f for f in os.listdir(folder) if f.lower().endswith(exts)]\n",
    "    names.sort()\n",
    "    return names\n",
    "\n",
    "def imread_rgb(path: str) -> Image.Image:\n",
    "    img = Image.open(path)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "def per_image_seed(global_seed: int, split: str, scale: int, stem: str) -> int:\n",
    "    s = f'{global_seed}|{split}|x{scale}|{stem}'\n",
    "    h = hashlib.sha256(s.encode('utf-8')).hexdigest()\n",
    "    return int(h[:8], 16)\n",
    "\n",
    "def _shift_array_edge(arr: np.ndarray, dx: int, dy: int) -> np.ndarray:\n",
    "    h, w = arr.shape[:2]\n",
    "    pad_l = max(0, dx); pad_r = max(0, -dx)\n",
    "    pad_t = max(0, dy); pad_b = max(0, -dy)\n",
    "    arr_pad = np.pad(arr, ((pad_t, pad_b), (pad_l, pad_r), (0,0)), mode='edge')\n",
    "    y0 = pad_t - dy; x0 = pad_l - dx\n",
    "    return arr_pad[y0:y0+h, x0:x0+w, :]\n",
    "\n",
    "def apply_motion_blur(img: Image.Image, ksize: int, angle_deg: float) -> Image.Image:\n",
    "    ksize = max(3, int(ksize) | 1)\n",
    "    angle = math.radians(angle_deg)\n",
    "    dx = math.cos(angle); dy = math.sin(angle)\n",
    "    arr = np.asarray(img).astype(np.float32)\n",
    "    acc = np.zeros_like(arr, dtype=np.float32)\n",
    "    n = ksize; center = (n - 1) / 2.0\n",
    "    for i in range(n):\n",
    "        offset = i - center\n",
    "        sx = int(round(offset * dx)); sy = int(round(offset * dy))\n",
    "        shifted = _shift_array_edge(arr, sx, sy)\n",
    "        acc += shifted\n",
    "    acc /= n\n",
    "    acc = np.clip(acc, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(acc)\n",
    "\n",
    "def apply_gaussian_blur(img: Image.Image, sigma: float) -> Image.Image:\n",
    "    if sigma <= 0.01:\n",
    "        return img\n",
    "    return img.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "\n",
    "def downsample(img: Image.Image, scale: int) -> Image.Image:\n",
    "    w, h = img.size\n",
    "    return img.resize((max(1, w // scale), max(1, h // scale)), Image.Resampling.BICUBIC)\n",
    "\n",
    "def add_gaussian_noise(img: Image.Image, std: float) -> Image.Image:\n",
    "    if std <= 0.01:\n",
    "        return img\n",
    "    arr = np.asarray(img).astype(np.float32)\n",
    "    noise = np.random.normal(0, std, arr.shape)\n",
    "    arr = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "def add_salt_pepper_noise(img: Image.Image, prob: float) -> Image.Image:\n",
    "    if prob <= 1e-5:\n",
    "        return img\n",
    "    arr = np.asarray(img).astype(np.uint8)\n",
    "    mask = np.random.rand(*arr.shape[:2])\n",
    "    salt = mask < (prob / 2)\n",
    "    pepper = (mask >= (prob / 2)) & (mask < prob)\n",
    "    arr[salt] = 255\n",
    "    arr[pepper] = 0\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "def add_jpeg_artifact(img: Image.Image, quality: int) -> Image.Image:\n",
    "    quality = int(max(1, min(quality, 100)))\n",
    "    with io.BytesIO() as buf:\n",
    "        img.save(buf, format='JPEG', quality=quality)\n",
    "        buf.seek(0)\n",
    "        return Image.open(buf).convert('RGB')\n",
    "\n",
    "def try_overlay(img: Image.Image, rng: random.Random):\n",
    "    if not os.path.isdir(OVERLAY_DIR) or rng.random() > OVERLAY_PROB:\n",
    "        return img, None, None\n",
    "    cand = [f for f in os.listdir(OVERLAY_DIR) if f.lower().endswith(('.png', '.webp'))]\n",
    "    if not cand:\n",
    "        return img, None, None\n",
    "    ov_name = rng.choice(cand)\n",
    "    ov = Image.open(os.path.join(OVERLAY_DIR, ov_name)).convert('RGBA')\n",
    "    s = rng.uniform(*OVERLAY_SCALE)\n",
    "    new_w = max(1, int(img.width * s))\n",
    "    new_h = max(1, int(ov.height * (new_w / max(1, ov.width))))\n",
    "    ov = ov.resize((new_w, new_h), Image.Resampling.BICUBIC)\n",
    "    x = rng.randint(-new_w // 2, img.width - 1)\n",
    "    y = rng.randint(-new_h // 2, img.height - 1)\n",
    "    alpha = rng.uniform(*OVERLAY_ALPHA)\n",
    "    r, g, b, a = ov.split()\n",
    "    a = a.point(lambda v: int(v * alpha))\n",
    "    ov = Image.merge('RGBA', (r, g, b, a))\n",
    "    base = img.convert('RGBA')\n",
    "    base.alpha_composite(ov, dest=(x, y))\n",
    "    return base.convert('RGB'), ov_name, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrade_one(hr_img: Image.Image, scale: int, rng: random.Random):\n",
    "    log = {}\n",
    "\n",
    "    # 1) Ê®°Á≥äÔºöÈ´òÊñØ/ËøêÂä® ‰∫åÈÄâ‰∏Ä\n",
    "    if rng.random() < 0.5:\n",
    "        sigma = rng.uniform(*BLUR_GAUSS_SIGMA)\n",
    "        lr = apply_gaussian_blur(hr_img, sigma)\n",
    "        log['blur_type'] = 'gaussian'\n",
    "        log['blur_sigma'] = round(sigma, 4)\n",
    "        log['motion_ksize'] = ''\n",
    "        log['motion_angle'] = ''\n",
    "    else:\n",
    "        ksz = rng.randrange(MOTION_KSIZE[0] | 1, (MOTION_KSIZE[1] | 1) + 1, 2)\n",
    "        ang = rng.uniform(*MOTION_ANGLE)\n",
    "        lr = apply_motion_blur(hr_img, ksz, ang)\n",
    "        log['blur_type'] = 'motion'\n",
    "        log['blur_sigma'] = ''\n",
    "        log['motion_ksize'] = int(ksz)\n",
    "        log['motion_angle'] = round(ang, 2)\n",
    "\n",
    "    # 2) ‰∏ãÈááÊ†∑\n",
    "    lr = downsample(lr, scale)\n",
    "    log['down_scale'] = int(scale)\n",
    "\n",
    "    # 3) Âô™Â£∞ÔºöÊó† / È´òÊñØ / Ê§íÁõêÔºàÊåâ 1/3 Ê¶ÇÁéáÔºâ\n",
    "    r = rng.random()\n",
    "    if r < 1/3:\n",
    "        log['noise_type'] = 'none'\n",
    "        log['noise_param'] = ''\n",
    "    elif r < 2/3:\n",
    "        std = rng.uniform(*GAUSS_NOISE_STD)\n",
    "        lr = add_gaussian_noise(lr, std)\n",
    "        log['noise_type'] = 'gaussian'\n",
    "        log['noise_param'] = round(std, 4)\n",
    "    else:\n",
    "        prob = rng.uniform(*SP_NOISE_PROB)\n",
    "        lr = add_salt_pepper_noise(lr, prob)\n",
    "        log['noise_type'] = 'salt_pepper'\n",
    "        log['noise_param'] = round(prob, 6)\n",
    "\n",
    "    # 4) JPEG ‰º™ÂΩ±\n",
    "    q = rng.randint(*JPEG_QUALITY)\n",
    "    lr = add_jpeg_artifact(lr, q)\n",
    "    log['jpeg_quality'] = int(q)\n",
    "\n",
    "    # 5) ÂèØÈÄâÂàíÁóï/Ê±°Ê∏çÂè†Âä†\n",
    "    lr, ov_name, ov_alpha = try_overlay(lr, rng)\n",
    "    log['overlay'] = ov_name or ''\n",
    "    log['overlay_alpha'] = round(ov_alpha, 3) if ov_alpha is not None else ''\n",
    "\n",
    "    return lr, log\n",
    "\n",
    "\n",
    "def make_lr_for_split(split: str, scale_list: List[int]):\n",
    "    hr_dir = os.path.join(DATA_ROOT, f'{split}_HR')\n",
    "    files = list_images(hr_dir)\n",
    "    if not files:\n",
    "        print(f'‚ö†Ô∏è Êú™ÂèëÁé∞ {hr_dir} ÂõæÂÉèÔºåË∑≥Ëøá {split}')\n",
    "        return {s:0 for s in scale_list}\n",
    "\n",
    "    lr_dir = os.path.join(DATA_ROOT, f'{split}_LR')\n",
    "    os.makedirs(lr_dir, exist_ok=True)\n",
    "\n",
    "    results = {}\n",
    "    for scale in scale_list:\n",
    "        print(f'ÂºÄÂßãÂ§ÑÁêÜ {split} x{scale}: ÂÖ± {len(files)} Âº†')\n",
    "        cnt = 0\n",
    "        for i, name in enumerate(files, 1):\n",
    "            stem, ext = os.path.splitext(name)\n",
    "            hr = imread_rgb(os.path.join(hr_dir, name))\n",
    "\n",
    "            s = per_image_seed(SEED, split, scale, stem)\n",
    "            rng = random.Random(s)\n",
    "            np.random.seed(s)\n",
    "\n",
    "            lr, log = degrade_one(hr, scale, rng)\n",
    "            out_name = f'{stem}x{scale}.png'\n",
    "            lr.save(os.path.join(lr_dir, out_name))\n",
    "\n",
    "            if i % 50 == 0 or i == len(files):\n",
    "                print(f'  Â∑≤ÂÆåÊàê {i}/{len(files)}')\n",
    "            cnt += 1\n",
    "\n",
    "        print(f'‚úÖ {split} x{scale} ÂÆåÊàêÔºöÁîüÊàê {cnt} Âº†')\n",
    "        results[scale] = cnt\n",
    "    return results\n",
    "\n",
    "\n",
    "total = 0\n",
    "for sp in SPLITS:\n",
    "    res = make_lr_for_split(sp, SCALES)\n",
    "    total += sum(res.values())\n",
    "print(f'üéâ ÂÖ®ÈÉ®ÂÆåÊàêÔºåÊÄªËÆ°ÁîüÊàê LRÔºö{total} Âº†')\n",
    "\n",
    "# ÂèØÈÄâÔºöÂø´ÈÄüÊ£ÄÊü• {split}_LR Êï∞Èáè‰∏éÂëΩÂêç\n",
    "check_scale = SCALES[0] if len(SCALES) == 1 else None\n",
    "if check_scale is not None:\n",
    "    for sp in SPLITS:\n",
    "        hr_dir = os.path.join(DATA_ROOT, f'{sp}_HR')\n",
    "        lr_dir = os.path.join(DATA_ROOT, f'{sp}_LR')\n",
    "        hr_files = list_images(hr_dir)\n",
    "        lr_files = list_images(lr_dir)\n",
    "        print(sp, 'HR:', len(hr_files), 'LR:', len(lr_files))\n",
    "        for n in hr_files[:5]:\n",
    "            stem, _ = os.path.splitext(n)\n",
    "            expect = f'{stem}x{check_scale}.png'\n",
    "            print('  ', n, '‚Üí', expect, 'Â≠òÂú®' if expect in lr_files else 'Áº∫Â§±')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
